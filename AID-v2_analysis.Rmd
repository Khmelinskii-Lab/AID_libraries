---
title: "Library v2 AID*-3Myc"
author: "EG"
date: "February 15, 2024"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 4
    toc_float: yes
    code_folding: show
editor_options: 
  chunk_output_type: console
---

# Introduction

This document contains the workflow for analysis of AID library experiment in 1 µM 5-Ph-IAA and the DNA Damage Agents (DDA) (library v2). Strains are plated on a control, in 1 µM of 5-Ph-indole-3-acetic acid (5-Ph-IAA) and the three DDA: Methyl methanosulfonate (MMS), Hydroxyurea (HU) and Camptothecin (CPT).


# Setup

Here, several functions and R packages that are necessary for the analysis are loaded.

```{r Setup 1, echo = FALSE}
setwd("~/Downloads/AID_libraries_3_AIDv2")

knitr::opts_chunk$set(echo = TRUE, fig.width = 24, fig.height = 12,
                      warning = FALSE, message = FALSE, error = TRUE)

```

```{r Setup 2 Functions}
# Function for loading and installing packages obtained from 
# https://stackoverflow.com/questions/4090169/elegant-way-to-check-for-missing-packages-and-install-them
# and adapted to current use case.
# @params ...: Package names as strings
LoadPackages <- function(...){
  
  libs <- unlist(list(...))
  req <- unlist(lapply(libs, require, character.only = TRUE))
  need <- libs[req == FALSE]
  n <- length(need)
  
  if(n > 0) {
    libsmsg <- if(n > 2) {
      paste(paste(need[1:(n-1)], collapse = ", "), ",", sep = "")
      } else { need[1] }
    
    print(libsmsg)
    
    if(n > 1) {
      libsmsg <- paste(libsmsg, " and ", need[n], sep = "")
      }
    
    libsmsg <- paste("The following packages could not be found: ", libsmsg,
                     "\n\r\n\rInstall missing packages?", collapse = "")
    
    if(winDialog(type = c("yesno"), libsmsg) == "YES") {
      install.packages(need)
      lapply(need, require, character.only = TRUE)
    }
  }
}

# Function for plotting heatmaps of colony sizes on a plate
# @params data_table: data frame containing plate number, row, column, and 
#   colony size data for plotting.
# @params plate_number: character or number indicating the plate to be plotted.
# @params fill_col: name of column containing colony size data
# @params source_type: string describing the colony size type (e.g. raw,
#   median-transformed, normalized)
# @params lowerlimit: number indicating the bottom of the plotted data
# @params midpoint: number indicating the median of the plotted data
# @params upperlimit: number indicating the ceiling of the plotted data
# @params breakpoints: number indicating the breaks for the scale
# @params na_colour: string indicating colour for NA values
heatplot <- function(data_table, plate_number,
                     fill_col = "size", source_type = "Raw",
                     lowerlimit = 0, midpoint = 500, upperlimit = 1000,
                     breakpoints = 200, na_colour = "white"){
  
  ## Install and load the package needed
  if (!requireNamespace("tidyverse", quietly = TRUE)) {
    install.packages("tidyverse")
  
  require(tidyverse)
  }
  
  ## Plotting the data using geom_tile from ggplot2
  ggplot(data = data_table %>%
           filter(plate_1536 == plate_number),
         aes(as.factor(col), reorder(as.factor(row), -row))) +
    geom_tile(aes_string(fill = fill_col)) +
    scale_fill_gradientn(name = paste0("Size (", source_type, ")"),
                         na.value = na_colour,
                         colours = c("lightblue1", "cyan", "black", "yellow3", "yellow"),
                         limits = c(lowerlimit, upperlimit),
                         breaks = seq(lowerlimit, upperlimit, breakpoints)
                         ) +
    coord_fixed(0.8) +
    theme_light(base_size = 26) +
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank()) +
    scale_y_discrete(limits = as.character(rev(seq(5, 28, 1))),
                     breaks = as.character(seq(5, 28, 1))) +
    scale_x_discrete(limits = as.character((seq(5, 44, 1))),
                     breaks = as.character(seq(5, 44, 1))) +
    labs(x = "Column", y = "Row",
         subtitle = paste("Plate", plate_number))

}

# Function needed for jackknife function (Taken from SGA Tools)
# @params x: a numeric vector
theta <- function(x){ sd(x, na.rm = T) }

# Function for GO Terms enrichment analysis
# @params background: data frame containing list of all ORFs in a screen with
#   GO Term information.
# @params input: data frame containing list of candidate ORFs from a screen with
#   GO Term information.
# @params BGlist: data frame with a column containing all ORFs (has to be same
#   list of ORFs with background)
# @params Inputlist: data frame with a column containing all candidate ORFs (has
#   to be same list of ORFs with input)
# @params error_table: empty data frame for GO terms that encounter a problem
EnrichGOTERMS <- function(background, input, BGlist, Inputlist){
  
  #### Preparation ####
    if (!requireNamespace("tidyverse", quietly = TRUE)) {
    install.packages("tidyverse")
  
  require(tidyverse)
  }
  
  ## List out all possible unique GO term identifiers as a list from the hits
  # GO parent term identifier is used to calculate p-values
  All_Possible_Identifiers <- unique(input$Gene.goAnnotation.ontologyTerm.parents.identifier)
  
  ## Count what is the number of unique GO term identifiers.
  unique_length <- length(All_Possible_Identifiers)
  
  ## Create a table to hold the calculated p-values from the previous hits table
  # P-value of each GO term is needed, so group by GO Terms
  newtable <- input %>%
    group_by(Gene.goAnnotation.ontologyTerm.parents.identifier,
             Gene.goAnnotation.ontologyTerm.parents.name,
             Gene.goAnnotation.ontologyTerm.parents.namespace) %>%
    # Name summary column as 'pval' which will be set to NA
    summarise(pval = n()) %>%
    ungroup %>%
    # Counts of number of ORFs in the hits and in the population are also needed
    mutate(pval = NA,
           Hits = NA,
           Population = NA)
  
  ## Enrichment calculation using hyper geometric distribution
  # A loop is used to go through all GO terms within the data set and perform
  #   the calculations needed.
  # 'All_Possible_Identifiers' is used here as it is from the background data
  #   and should encompass all the terms for the hits as well.
  for(x in 1:unique_length) {
    
    ## Print message to show which GO ID is being checked
    print(paste0(x, "/", unique_length,
                 " Analyzing GO ID: ", All_Possible_Identifiers[x],
                 " - GO Term: ", unique((background %>%
           filter(Gene.goAnnotation.ontologyTerm.parents.identifier ==
                    All_Possible_Identifiers[x])
           )$Gene.goAnnotation.ontologyTerm.parents.name)))
    
    ## Perform calculations
    # Calculate all the needed data/numbers for phyper function
    # The number of ORFs must be unique and not repeated for each GO Term
    
    hits_anno <- length(unique(
      (input %>%
         filter(Gene.goAnnotation.ontologyTerm.parents.identifier ==
                  All_Possible_Identifiers[x])
       )$Gene.secondaryIdentifier))
    
    pop_anno <- length(unique(
      (background %>%
         filter(Gene.goAnnotation.ontologyTerm.parents.identifier ==
                  All_Possible_Identifiers[x])
       )$Gene.secondaryIdentifier))
    
    hits_length <- nrow(Inputlist)
    
    pop_length <- nrow(BGlist)
    
    # P-value is calculated using phyper function as annotated on the
    # YeastMine API documentation
    pvalue <- phyper(q = hits_anno-1, m = pop_anno,
                     n = pop_length-pop_anno, k = hits_length,
                     lower.tail = FALSE)
  
    ## Store the calculated p-value and ORF counts
    newtable$pval[newtable$Gene.goAnnotation.ontologyTerm.parents.identifier ==
                    All_Possible_Identifiers[x]] <- pvalue
    
    newtable$Hits[newtable$Gene.goAnnotation.ontologyTerm.parents.identifier ==
                    All_Possible_Identifiers[x]] <- hits_anno
    
    newtable$Population[newtable$Gene.goAnnotation.ontologyTerm.parents.identifier ==
                          All_Possible_Identifiers[x]] <- pop_anno
    }
  
  return(newtable)
  
}

```

```{r Setup 3 Directory, Packages n Datasets}
# Getting the main working directory
PrimaryDirectory = getwd()

# Loading the required R packages
LoadPackages("tidyverse", "kableExtra", "gdata", "openxlsx", "gridExtra", "grid", "patchwork", "VennDiagram", "EnvStats", "janitor","pheatmap")

# Setting the ggplot theme
theme_set(theme_light(base_size = 26))

# Listing the rows for a 1536 array
alphabet1536 <- c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L",
                  "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X",
                  "Y", "Z", "AA", "AB", "AC", "AD", "AE", "AF")

alphabet1536_rev <- 1:length(alphabet1536)
names(alphabet1536_rev) <- alphabet1536

# Import an Excel file containing the coordinates of the border colonies
BorderColonies <- read.xlsx(xlsxFile = "BorderColoniesList.xlsx", sheet = "Sheet1")

```


## SGA Tools

Additionally, SGA tools from https://github.com/boonelab/sgatools/blob/master/public/SGAtools/SGAtools.R are loaded for the normalizing functions that will be used in this analysis. The functions related to normalization were modified as described below.

```{r Setup SGA tools}
####################################################################################
# SGATools v1.2.1
# Tools for image processing, normalizing and scoring Synthetic Genetic Array screens.
#
# This software is in the public domain, furnished "as is", without technical
# support, and with no warranty, express or implied, as to its usefulness for
# any purpose.
#
# Author:         Omar Wagih
# Licence:        Academic Free Licence v3.0
# Language:       English (CA)
# Last modified:  19/11/12
# 
# Modification History 
# --------------------
# Dated  Version		Who		Description
# ----------------------------------------------------------
# 2020-05  1.1     JF    Edited normalizeSGA function as described below:
#     1)  Removed parameters 'keep.large', "intermediate.data", "linkage.file",
#         "linkage.genes". Creates issues because the parameters are not used.
#     2)  Changed "max.colony.size" param to 3*overall.plate.median
#     3)  Added new parameter "field.to.normalize" because we have different entry
#         points and the column is called differently to the default in the code
#     4)  Changed num.rows and num.cols to get the information from the global
#         environment instead of the data table.
#     5)  Removed "rdbl", "cdbl", and "spots" because of difference in the data
#         table setup
#     6)  Removed (F1) Linkage effect filter
#     7)  For (N1) plate normalization, changed 'colonysize' to parameter called
#         "field.to.normalize"
#     8)  Removed (F2) Big replicates filter
#     9)  Removed (F3) Jackknife filter. This is done later in the analysis at
#         a different point in the analysis.
#     10) Removed setting data to "ncolonysize", capping normalized colony size,
#         and adding status codes steps.
#     11) Removed all items after (N4) Plate Normalization 2, and immediately
#         return plate data after this step.
# 2020-05  1.1     JF    Edited spatialNormalization function as described below:
#     1)  Changed num.rows and num.cols to get the information from the global
#         environment instead of the data table.
#     2)  Removed line where ignore indices is set to NA:
#         ("after.ignore[ignore.ind] = NA")
# 2020-05  1.1     JF    Edited rowcolNormalization function as described below:
#     1)  Removed line where ignore indices is set to NA:
#         ("after.ignore[ignore.ind] = NA")
#     2)  Changed num.rows and num.cols to get the information from the global
#         environment instead of the data table.
# 2020-05  1.1     JF    Edited rowcolNormalizationHelper function as described below:
#     1)  Modified the section to determine window size to be used in lowess
#     2)  Simplified the lowess calculation section
# 2020-05  1.1     JF    Edited fgaussian function as below:
#     1)  Changed the seq helper function to SGAseq because of the change in
#         name of the function
# 2020-05  1.1     JF    Edited seq function as described below:
#     1)  Renamed the function to SGAseq as it was interfering with the base
#         seq() function
# 2020-10  1.2     JF    Packages loading modified
#     1)  Use LoadPackages() to load required libraries
# 2023-10  1.2.1     EG    Normalized size values changed
#     1)  Median and MAD calculated with the colonies between 40-80% of the plate size 
#     2)  The row and col normalization was deleted due to overnormalization of
#         colonies size.
####################################################################################

# Load required libraries 
# "logging" is for log file
# "stringr" is for regex matching functions
# "bootstrap" is for jackknife function
LoadPackages("logging", "stringr", "bootstrap")


addHandler(writeToConsole)

# returns string w/o leading whitespace
trim.leading <- function (x)  sub("^\\s+", "", x)

# returns string w/o trailing whitespace
trim.trailing <- function (x) sub("\\s+$", "", x)

# returns string w/o leading or trailing whitespace
trim <- function (x) gsub("^\\s+|\\s+$", "", x)

SGATOOLS_VERSION = '1.2'
####################################################################################
# Reading section
readSGA <- function(file.paths, file.names=basename(file.paths), ad.paths=NA, replicates=4){
  
  # Length of vectors
  n1 = length(file.paths)
  n2 = length(file.names)
  
  loginfo('Reading input files')#
  
  sga.data.list = lapply(file.paths, function(file.path){
    # Index of the file path
    file.ind = which(file.paths == file.path)
    
    # Name of file 
    file.name = file.names[file.ind]
    
    loginfo('Reading input file (%d/%d) path = %s', file.ind, n1, file.path)
    
    # Read all lines first line, except @ and # symbols
    file.lines = readLines(file.path) 
    comment.meta = file.lines[grepl('@|#|[(]', file.lines)]
    file.lines = file.lines[!grepl('@|#|[(]', file.lines)]
    
    # If first line is Colony Project Data File, skip the first 13 lines 
    if(grepl('Colony Project Data File', file.lines[1], ignore.case=T)){
      loginfo('* Detected boone-lab format, skipping first 13 lines')
      file.lines = file.lines[-(1:13)]
      file.lines = sapply(file.lines, trim)
      file.lines = gsub(pattern='\\s+',replacement='\t',file.lines)
    }
    
    # Read in the data: we only care about the first 3 columns
    sga.data = read.delim(textConnection(file.lines), stringsAsFactors=F, header=F)[1:3]
    names(sga.data) = c('V1', 'V2', 'V3')
    sga.data = sga.data[with(sga.data, order(V1, V2)), ]
    
    loginfo('* Done reading')
    
    # Find number of rows and columns
    num.rows = max(sga.data[[1]])
    num.cols = max(sga.data[[2]])
    
    loginfo('* Column classes = %s', sapply(sga.data, class))
    loginfo('* Number rows = %d', num.rows)
    loginfo('* Number cols = %d', num.cols)
    loginfo('* Data dimension = %s', dim(sga.data))
    
    file.name.metadata = fileNameMetadata(file.name)
    
    loginfo('* Obtaining file name metadata: valid = %s', file.name.metadata$is.valid)
    
    # Add plate id as file name
    sga.data[[4]] = file.name.metadata$filename
    
    rdbl = ceiling(sga.data[[1]]/sqrt(replicates))
    cdbl = ceiling(sga.data[[2]]/sqrt(replicates))
    
    # Default query - index of file
    sga.data[[5]] = as.character(file.ind)
    
    # Do we have valid meta data in the file name
    if(file.name.metadata$is.valid){
      # Update query
      sga.data[[5]] = file.name.metadata$query
    }
    
    # Default arrays as numbers - each replicate has a unique number 
    array.vals = ((cdbl - 1)* (num.rows/sqrt(replicates))) + rdbl
    
    # Map to array definition files
    sga.data[,6:7] = mapArrayDefinition(file.name.metadata, array.vals, 
                                       rdbl, cdbl, ad.paths)
    
    # Set normalized colony size / score / KVP to NA 
    sga.data[,8:10] = NA
    
    # Add comment / meta data lines
    comment(sga.data) = comment.meta
    
    # Add other attributes
    attr(sga.data, 'file.name.metadata') = file.name.metadata
    attr(sga.data, 'num.rows') = num.rows
    attr(sga.data, 'num.cols') = num.cols
    
    # Set column names of data
    names(sga.data) = c('row', 'col', 'colonysize',
                        'plateid', 'query','array', 'array_annot',
                        'ncolonysize', 'score', 'kvp'  )
    sga.data
  })
  
  loginfo('Done reading all files')
  loginfo('-----------------------------------------------')
  return(sga.data.list)
}

mapArrayDefinition <- function(file.name.metadata, array.vals, rdbl, cdbl, ad.paths){
  # If we have array definition files - i.e they are not all NA
  if(! all(is.na(ad.paths))){
    loginfo('* Mapping array definition: number of array definition files = %d', length(ad.paths))
    
    # Get file names of paths
    ad.basenames = basename(ad.paths)
    
    ap.ids = str_extract(tolower(ad.paths), 'plate\\d+')
    if (is.na(ap.ids)) {
        loginfo('* Cherry picker plate name malformed... assume only one plate is available')
        ap.ids = c(file.name.metadata$arrayplateid)
    } else {
        ap.ids = as.numeric(str_extract(ap.ids, '\\d+'))
    }
    
    loginfo('* Mapping array definition: IDs of array plate files = %s', ap.ids)
    
    # Assume no valid array plate id, use the first one we have
    ind = 1
    
    if(file.name.metadata$is.valid){
      # If our file has a valid array plate id, match it to its array definition file path
      ind = which(file.name.metadata$arrayplateid == ap.ids)[1]
    }
    
    if(!is.na(ind)){
      # Read in corresponding array definition file - handle 5 lines?
      ad.data = read.table(ad.paths[ind], sep='\t', skip=5, header=F, stringsAsFactors=F)
      names(ad.data)[1:3] = c('c', 'r', 'Gene')
      
      m=data.frame(r=rdbl, c=cdbl)
      i = apply(m, 1, function(x){
        intersect(which(x[1] == ad.data$r), which(x[2] == ad.data$c))[1]
      })
      good.ind = !is.na(i)
      array.vals[good.ind] = ad.data$Gene[i][good.ind]
    }
    
  }else{
    loginfo('* Not mapping array definition: no array definition files')
  }
  
  ret = as.character(array.vals)
  
  orfs = unlist( lapply(strsplit(ret, '_'), function(i) i[1]) )
  annots = unlist( lapply(strsplit(ret, '_'), function(i) i[2]) )
  
  if (all(is.na(annots))) {
    annots = orfs
  }
  
  return(c(orfs, annots))
}

# Get metadata encoded in file name
# Format should be: username_query_arrayplateid...
# @param file.name: character file name
# @return ret: list of all meta data encoded in file name
fileNameMetadata <- function(file.name){
  split.pat =  '_|\\.'
  
  sp = strsplit(file.name,split.pat)[[1]]
  
  # Regular expression query of control screens
  ctrl.pat = 'wt|ctrl'
  # Regular expression for digit
  digit.pat = '^\\d+$'
  
  ret = NULL
  
  # Set file name - replace any spaces by a hyphen
  ret$filename = sub('\\s', '-', file.name)
  
  # Set user name - replace any spaces with a hyphen
  ret$username = sub('\\s', '-', sp[1])
  
  # Set query name
  ret$query = sub('\\s', '-', sp[3])
  
  # Set is.control
  ret$is.control = grepl(ctrl.pat, sp[2], ignore.case=T)
  
  # Set array plate id
  if(grepl(digit.pat, sp[4])){
    # Valid array plate id
    ret$arrayplateid = as.numeric(sp[4])
  }else{
    # Invalid array plate id
    ret$arrayplateid = NA
  }
  
  # Set is valid only if we have no NAs 
  ret$is.valid = !any(is.na(c(ret$query, ret$arrayplateid)))
  
  return(ret)
}

####################################################################################
# Normalization/scoring section

# Normalize a plate
# @params overall.plate.median: value of overall plate median from large-scale experiments
# @params max.colony.size: computed from plate median, used to filter large colonies
# @return data frame: normalized data frame
# The normalizeSGA function was edited from the original
normalizeSGA <- function(
        plate.data,
        overall.plate.median = 510,
        max.colony.size = 3*overall.plate.median, # Changed this to 3 to keep everything. Threshold filter is done later.
        field.to.normalize = 'size'
		){
  
  loginfo('Normalizing plate: overall.plate.median = %d, max.colony.size = %d, nROW = %d, nCOL = %d', 
          overall.plate.median, max.colony.size, nROW, nCOL)

  # Edited so it is filled in at the start of the function with nROW and nCOL from the global environment.
  num.rows = nROW
  num.cols = nCOL

  # Ignored rows (not used as we are not filtering; kept for ease of the rest of the code)
  ignore.ind = rep(FALSE, nrow(plate.data))
  names(ignore.ind) = NA
 
  ########## (N1) Plate normalization ##########
  plate.data$pnorm = plateNormalization(plate.data, field.to.normalize, overall.plate.median)

  ########## (N2) Spatial normalization ##########
  # The spatialNormalization function was edited from the original
  plate.data$snorm = spatialNormalization(plate.data, 'pnorm', ignore.ind)

  ########## (N3) Row column effect normalization ##########
  # The rowcolNormalization function was edited from the original
 # plate.data$rcnorm = rowcolNormalization(plate.data, 'snorm', ignore.ind)

  ########## (N4) Plate normalization 2 ##########
  plate.data$pnorm2 = plateNormalization(plate.data, 'snorm', overall.plate.median)
  
  # The last section on normalizing to the overall plate median is removed.
  
  return(plate.data)
}

# Score plates
# @params plate.data.list: list of data frames (plate data)
# @params scoring.function: 1 for Cij-CiCj, 2 for Cij/CiCj
# @return list: list of plate files, scored
scoreSGA <- function(plate.data.list, scoring.function=1){
  
  # Merge list info
  merged.dat = do.call('rbind', plate.data.list)
  
  metadata.table = lapply(plate.data.list, function(plate.data){
    d = attr(plate.data, 'file.name.metadata')
    as.data.frame(d)
  })
  metadata.table = do.call('rbind', metadata.table)[,4:6]
  
  # If we dont have any control/dm plates, we cant do scoring
  if(sum(metadata.table$is.control) < 1 | sum(!metadata.table$is.control) < 1)
    return(plate.data.list)
  
  # Do scoring for different array plate ids separatley 
  for(arrayplateid in unique(metadata.table$arrayplateid)){
    
    # Check if this array plate id has controls. if not, dont do anything
    is.ctrl = metadata.table$is.control & metadata.table$arrayplateid == arrayplateid
    is.dm = !metadata.table$is.control & metadata.table$arrayplateid == arrayplateid
    
    if(sum(is.ctrl) < 1 | sum(is.dm) < 1)
      next
    
    merged.dat.ctrl = do.call('rbind', plate.data.list[is.ctrl])
    merged.dat.dm = do.call('rbind', plate.data.list[is.dm])
    
    # We have at least one query, proceed to score
    # Get single mutant fitness of arrays (non control plates) - computed as median of the plate
    querys = unique(merged.dat.dm$query)
    query.smf = sapply(querys, function(curr.query){
      median( merged.dat.dm$ncolonysize[merged.dat.dm$query == curr.query] , na.rm=T)
    })
    
    # Get array smf from control plates
    arrays = unique(merged.dat.ctrl$array_annot)
    array.smf = sapply(arrays, function(curr.array){
      median( merged.dat.ctrl$ncolonysize[ merged.dat.ctrl$array_annot == curr.array ], na.rm=T )
    })
    
    # Use default overall median or median from plates?
    # Default overall median
    overall.median = 510
    # Get 60% middle median - R automatically removes NA values
    vals = sort(merged.dat$ncolonysize)
    length = length(vals)
    lower = 0.4
    upper = 0.8
    middle.median = median( vals[round(lower*length):round(upper*length)], na.rm = T)
    
    # Do the scoring
    plate.data.list[is.dm] = lapply(plate.data.list[is.dm], function(plate.data){
      # Single mutant fitnesses
      q.smf = query.smf[plate.data$query] / middle.median
      a.smf = array.smf[plate.data$array_annot] / middle.median
      # Double mutant fitness
      dm = plate.data$ncolonysize / middle.median
      
      # Score accourding to scoring function
      if(scoring.function == 1){
        plate.data$score = dm - (q.smf * a.smf)
      }else if(scoring.function == 2){
        plate.data$score = dm / (q.smf * a.smf)
      }
      
      plate.data$ctrlncolonysize = plate.data.list[is.ctrl][[1]]$ncolonysize;
      
      plate.data
    })
    
  }# End array plate id loop
  
  # Done scoring, return the data
  return(plate.data.list)
}

# Merges names of logical vectors, collapsing using a comma
# @param a: logical vector 1
# @param b: logical vector 2
# @return logical: logical vector 1 and 2 merged
mergeLogicalNames <- function(a, b){
  ret = a | b
  sp1 = strsplit( names(a), ',')
  sp2 = strsplit( names(b), ',')
  
  new.nm = sapply(1:length(sp1), function(i){
    u = as.character(union(sp1[[i]], sp2[[i]]))
    u = u[!is.na(u) & !grepl('NA', u)]
    paste(u, collapse=',')
  })
  names(ret) = new.nm
  return(ret)
}

#  Key-value pair methods
# Convert character vector of kvps to a data frame
# @param kvps.string: character verctor of kvps  
# @return data frame: columns are keys, rows are different kvps
kvpsAsDataFrame <- function(kvps.string){
  # Get list of dataframes
  list.df = lapply(kvps.string, function(kvp.string){
    if(!is.na(kvp.string)){
      df = as.data.frame(kvpAsMap(kvp.string))
      t(df)
    }
  })
  # Remove NULL
  list.df = list.df[!sapply(list.df, is.null)]
  
  # If nothing produced we return an empty data frame
  if(length(list.df) == 0) return(as.data.frame(matrix(NA,0,0)))
  
  #Merge keys/value data frames
  merged.df = Reduce(function(...) merge(..., all=T), list.df)
  
  # Rename so everything is uppercase
  names(merged.df) = toupper(names(merged.df))
  return(merged.df)
}

# Convert key-value pair string to key-value map 
# @param kvp.string: key value pair as character 
# @return list: named vector
kvpAsMap <- function(kvp.string){
  # As a vector
  split = strsplit(kvp.string, '\\{|\\}|,\\s*')[[1]]
  split = split[split != ""]
  
  # Create the map
  df = as.data.frame(strsplit(split, '='), stringsAsFactors=F)
  map = as.character(df[2,])
  names(map) = df[1,]
  
  return(map)
}

# Convert key-value pair map to a character string 
# @param kvp.map: key value pair as map 
# @return list: character representation
kvpMapAsString <- function(kvp.map){
  kv = sapply(names(kvp.map), function(key){
    paste0(key, '=', kvp.map[[key]])
  })
  return(paste0('', paste0(kv, collapse=','), ''))
}

# Linkage filter: check if query and array are within close proximity on the same chromosome
# @param plate.data: SGA formatted data frame
# @param linkage.cutoff: in KB, If witin this value of eachother on same chromosome they will be ignored
# @return linkage.ignore: logical array with TRUE for rows to ignore. Status code as name
linkageFilter <- function(plate.data, linkage.cutoff=200, linkage.file='', linkage.genes=''){
  
  loginfo('# Applying linkage filter, linkage.cutoff = %d', linkage.cutoff)
  
  loginfo('Linkage file is at: %s', linkage.file)
  status.code = 'LK'
  
  # Load linkage files named: chromosome_coordinates.Rdata(R.data?)
  if(file.exists(linkage.file)){
    loginfo('Loading chromosome coordinates file')
    load('data/chrom_coordinates.Rdata')
  }else{
    loginfo('Chromosome coordinates file does not exist, returning empty data frame')
    chrom_coordinates = as.data.frame(matrix(NA, 0, 4))
  }
  
  if(linkage.cutoff < 0){
    loginfo('Skipping linkage correction...')
    linked = rep(FALSE, nrow(plate.data))
    names(linked) = NA
    return(linked)
  }
  
  
  mid.map = apply(chrom_coordinates[,3:4], 1, mean)
  names(mid.map) = chrom_coordinates[[1]]
  
  chr.map = chrom_coordinates[[2]]
  names(chr.map) = chrom_coordinates[[1]]
  
  linkage.genes = unique(c(plate.data$query, linkage.genes))
  loginfo('# Linkage genes including query = %s', paste0(linkage.genes, collapse=', '))
  linkage.genes = linkage.genes[ linkage.genes %in% chrom_coordinates[[1]] ]
  loginfo('# Linkage genes found in coords table = %s', paste0(linkage.genes, collapse=', '))
  
  # Get indicies for which row:query/array on same chromsome and within < cutoff
  #ind = plate.data$array %in% chrom_coordinates[[1]] 
  ar = plate.data$array
  
  linked = sapply(linkage.genes, function(g){
    (chr.map[g] == chr.map[ar]) & (abs( mid.map[g] - mid.map[ar] ) < (linkage.cutoff * 1e3))
  })
  
  linked = apply(linked, 1, any)
  linked[is.na(linked)] = FALSE
  
#   linked = sapply(plate.data$array, function(ar){
#     if(length(linkage.genes) == 0 | ! ar %in% chrom_coordinates[[1]] | linkage.genes[1] == ''){
#       FALSE
#     }else{
#       t = sapply(linkage.genes, function(g){
#         (chr.map[g] == chr.map[ar]) & (abs( mid.map[g] - mid.map[ar] ) < (linkage.cutoff * 1e3))
#       })
#       if(any(is.na(t) | is.null(t))){
#         FALSE
#       }else{
#         any(t)
#       }
#     }
#   })
  
  # Set status code
  names(linked) = NA
  ind = which(linked)
  names(linked)[ind] = rep(status.code, length(ind))
  
  loginfo('Linkage filter applied, total ignored = %d',sum(linked))
  return(linked)
}

# Plate normalization: brings all plates to one same scale
# @param plate.data: SGA formatted data frame
# @param field.to.normalize: name of the column in the data to normalize
# @return: vector of normalized values
plateNormalization <- function(plate.data, field.to.normalize, default.overall.median) {
  
  loginfo('# Normalizing for plate effect, default.overall.median = %d', default.overall.median)
  #Used to get median of center 60% of colonies (change if needed)
  lower = 0.4
  upper = 0.8
  
  # Get and sort our data to be plate normalized
  vals = sort(plate.data[[field.to.normalize]])
  vals.length = length(vals)
  
  # If we have insufficient data - return NAs
  if(length(vals) < 10){
    loginfo('Insufficient data for plate normalization, returning')
    return( rep(NA, nrow(plate.data)) )
  }
  
  # We have sufficient data - get median of center 60% of colonies
  plate.median = median(vals[round(lower*vals.length) : round(upper*vals.length)], na.rm = TRUE)
  
  if (plate.median == 0) {
    loginfo('Median is 0, taking median of all')
    plate.median = mean(vals, na.rm = TRUE)
    loginfo(paste('New median is', plate.median))
  }
  
  # Store the final result computed using all data in result array
  normalized = plate.data[[field.to.normalize]] * (default.overall.median / plate.median)
  
  loginfo('Done plate normalization')
  
  # Return final result
  return(normalized)
}

# Spatial normalization: normalizes any gradient effect on the plate via median smoothing
# @param plate.data: SGA formatted data frame
# @param field.to.normalize: name of the column in the data to normalize
# @param ignore.ind: logical for any rows to be ignored 
# @return: vector of normalized values
# The spatialNormalization function was edited from the original
spatialNormalization <- function(plate.data, field.to.normalize, ignore.ind) {

  loginfo('# Normalizing for spatial effect')

  # Edited so it is filled in at the start of the function with nROW and nCOL from the global environment.
  num.rows = nROW
  num.cols = nCOL
  
  # Get gaussian/average filters
  gaussian.filt = fgaussian(7, 2) # smaller number, better resolution between neighbouring colonies
  average.filt = faverage(9)
  
  # Data to be normalized before ignored
  before.ignore = plate.data[[field.to.normalize]]
  
  # Data to be normalized after ignored (used in the analysis)
  after.ignore = before.ignore
  
  # Construct plate matrix
  plate.mat = matrix(NA, num.rows, num.cols)
  rc.mat = as.matrix(plate.data[,1:2])
  plate.mat[rc.mat] = after.ignore
  
  # Fill NA with a placeholder (mean of all colonies) 
  t = plate.mat
  ind.na = which(is.na(t))
  t[ind.na] = mean(plate.mat, na.rm = TRUE)
  
  # Fill in NA with smoothed version of neighbors using gaussian blur
  filt.g = applyfilter(t, gaussian.filt)
  t[ind.na] = filt.g[ind.na]
  
  # Apply median/average filters
  # Padding type "replicate" is to copy nearest cells and this way it makes the border colonies have more large sized colonies on an outer "fake" border to normalise it.
  filtered = medianfilter2d(t, 7, padding_type = 'replicate')
  filtered = applyfilter(filtered, average.filt, 'replicate')
  
  # Subtract the mean of the filtered data from the filtered data
  f = filtered / mean(filtered)
  
  # Subtract filtered - mean from  
  before.ignore = before.ignore / f[rc.mat]
  
  return(before.ignore)
}

# Row column effect normalization
# @param plate.data: SGA formatted data frame
# @param field.to.normalize: name of the column in the data to normalize
# @param ignore.ind: logical for any rows to be ignored 
# @return: vector of normalized values
# The rowcolNormalization function was edited from the original
rowcolNormalization <- function(plate.data, field.to.normalize, ignore.ind) {
  
  loginfo('# Normalizing for row column effect')

  # Data before rows ignored
  data.before.ignore = plate.data[[field.to.normalize]]
  
  # Ignore these rows
  data.after.ignore = data.before.ignore
  
  # Edited so it is filled in at the start of the function with nROW and nCOL from the global environment.
  num.rows = nROW
  num.cols = nCOL
  
  # Smooth across columns
  # The rowcolNormalizationHelper function was edited from the original
  col.data = plate.data$col
  norm.col.effect = rowcolNormalizationHelper(col.data, data.after.ignore, num.rows, num.cols)
  
  # Smooth across rows
  # The rowcolNormalizationHelper function was edited from the original
  norm.col.effect[ignore.ind] = NA
  row.data = plate.data$row
  norm.rowcol.effect = rowcolNormalizationHelper(row.data, norm.col.effect, num.rows, num.cols)
  
  return(norm.rowcol.effect)
}

# Helper for row/column effect normalization to avoid redundancy 
# @param rowcol.data: values of the row/col column in the plate data frame
# @param colony.size.data: values of the colony sizes being normalized 
# @return: vector of normalized values
# The rowcolNormalizationHelper function was edited from the original
rowcolNormalizationHelper <- function(rowcol.data, colony.size.data, num.rows, num.cols){
  
  ind.na = is.na(colony.size.data)
  
  # Sort values with index return
  vals.sorted = sort(rowcol.data[!ind.na], index.return = TRUE)
  ind.sorted = vals.sorted[[2]]
  vals.sorted = vals.sorted[[1]]
  
  # Original code start
  # Window size to be used in lowess smoothing - currently not using it
  #span = sum(vals.sorted <= 6) / (num.rows*num.cols)
  
  #if(span>0 & length(span) > 0){
  #lowess_smoothed = lowess(rowcol.data[!ind.na][ind.sorted], colony.size.data[!ind.na][ind.sorted], f=0.09, iter=5)
  #}else{
  #  lowess_smoothed = list(y=colony.size.data[!ind.na][ind.sorted])
  #}
  # Original code end
  
  #Modified
  lowess_smoothed = lowess(rowcol.data[!ind.na][ind.sorted], colony.size.data[!ind.na][ind.sorted], f = 0.09, iter = 5)
  
  #      pdf(sprintf('~/Desktop/lowess_%s_%s.pdf', max(rowcol.data, na.rm=T), i), width=18, height=18)
  #      x = rowcol.data[!ind.na][ind.sorted]
  #      y = colony.size.data[!ind.na][ind.sorted]
  #      plot(x,y)
  #      lines(lowess_smoothed, col='green')
  #      lx = lowess_smoothed$x
  
  # We only care about Y values (colony size)
  lowess_smoothed = lowess_smoothed[['y']]
  
  tmp = lowess_smoothed / mean(lowess_smoothed)
  tmp[is.nan(tmp)] = 1
  colony.size.data[!ind.na][ind.sorted] = colony.size.data[!ind.na][ind.sorted] / tmp;
  colony.size.data[is.infinite(colony.size.data)] = 0
  
  #    lines(x=lx, tmp, col='red')
  #    points(x=lx, colony.size.data[!ind.na][ind.sorted] / tmp, col='blue', pch=3)
  #    dev.off()
  
  # Fill ignored NA values
  ind.uniq.rc = which(duplicated(rowcol.data))
  rc.to.smoothed = lowess_smoothed[ind.uniq.rc]
  names(rc.to.smoothed) = rowcol.data[ind.uniq.rc]
  
  ind.na = which(ind.na)
  
  na.smoothed = sapply(ind.na, function(i){
    i.rc = as.character(rowcol.data[i]) 
    
    i.smoothed = rc.to.smoothed[i.rc]
    
    i.smoothed / mean(lowess_smoothed)
  })
  na.smoothed = unlist(na.smoothed)
  
  # Update NAs
  colony.size.data[ind.na] = colony.size.data[ind.na] / as.vector(na.smoothed)
  
  return(colony.size.data)
}

# Jackknife filter (LOOCV): checks for colonies that contribute more than 90% of total variance in their replicates
# @param plate.data: SGA formatted data frame
# @param field.to.filter: name of the column in the data to filter
# @return jk.ignore.logical: logical array with TRUE for rows to ignore. Status code as name
jackknifeFilter <- function(plate.data, field.to.filter){
  
  loginfo('# Applying jackknife filter')
  
  # Status code of filter
  status.code = 'JK'
  
  # Get all unique queries
  uniq.query = unique(plate.data$query)
  
  # Get all unique arrays
  uniq.array = unique(plate.data$array)
  uniq.spots = unique(plate.data$spots)
  
  # Remove HIS3 from arrays
  uniq.array = uniq.array[ ! grepl('YOR202W', uniq.array, ignore.case=T) ]
  uniq.spots = uniq.spots[ ! grepl('YOR202W', uniq.array, ignore.case=T) ]
  
  # Function used for jackknife function (sd, ignoring NA)
  theta <- function(x){sd(x, na.rm=T)}
  
  jk.ignore = lapply(uniq.spots, function(curr.spot){
    
    # Ignore HIS3 from arrays
    # if( grepl('YOR202W', curr.array, ignore.case=T) ) NULL
    
    curr.ind = which(plate.data$spot == curr.spot)
    # Get indices of our current array
    vals = plate.data[[field.to.filter]][curr.ind]
    # Get NA values
    ind.na = is.na(vals)
    
    # If we dont have enough non-NA values
    if( sum(!is.na(vals))  < 2 ) NULL
    
    # Get jackknife variances 
    jk.vals = jackknife(vals, theta)$jack.values
    
    # Get total variance and jackknife variances
    total.var = var(vals, na.rm=T) * (length(vals)-1)
    jk.var =  (jk.vals^2) * (length(jk.vals)-2)
    
    # Find colonies that contribute more than 90% of total variance
    t = which( (total.var - jk.var) >  (0.9*total.var) )
    curr.ind[t]
  })
  
  # These are the indicies to be ignored
  jk.ignore.ind = unlist(jk.ignore[! sapply(jk.ignore, is.null)])
  
  # Turn into logical values i.e. if we had indicies 1, 3 to be ignored, 
  # it will be converted to TRUE FALSE TRUE FALSE FALSE ......
  jk.ignore.logical = 1:nrow(plate.data) %in% jk.ignore.ind
  
  # Add status code JK - jackknife failed
  names(jk.ignore.logical) = NA
  names(jk.ignore.logical)[jk.ignore.ind] = rep(status.code, length(jk.ignore.ind))
  
  loginfo('Done jackknife filter, total ignored = %d', sum(jk.ignore.logical))
  return(jk.ignore.logical)
}

# Big replicates filter: remove excessively large colonies replicates
# @param plate.data: SGA formatted data frame
# @param field.to.filter: name of the column in the data to filter
# @param max.colony.size: "large" colony threshhold, usually 1.5 * median of plate
# @return big.logical: logical array with TRUE for rows to ignore. Status code as name
bigReplicatesFilter <- function(plate.data, field.to.filter, max.colony.size, ignore.ind){
  
  loginfo('# Applying big replicates filter, max.colony.size = %d', max.colony.size)
  # Status code of filter
  status.code = 'BG'
  
  #Find indicies of large colonies
  large.ind = which(plate.data[[field.to.filter]] >= max.colony.size)
  
  # Gets spots of large colonies, and returns the count of each spot
  big.spots = table(plate.data$spots[large.ind])
  
  # Get colonies such that their spot contains at least 3 big colonies
  big.spots = big.spots[big.spots >= 3]
  spots.to.remove = names(big.spots)
 
  # Get which colonies are in spots to remove
  big.ind = which(plate.data$spots %in% spots.to.remove)
  
  big.logical = 1:nrow(plate.data) %in% big.ind
  
  # Set status code BG BIG REP?
  names(big.logical) = NA
  names(big.logical)[big.ind] =  rep(status.code, length(big.ind))
  
  loginfo('Done big replicates filter, total ignored = %d', sum(big.logical))
  return(big.logical)
}


####################################################################################
# Filter functions used in spatial normalization: rewritten from matlab for R 

# Returns a gaussian filter matrix with dimensions x by x: equal to fspecial function in matlab
# Inputs:
# x = dimensions (number of rows/cols) of the returned gaussian filter
#	sigma = standard deviation
# The fgaussian function was edited from the original
fgaussian <- function(x, sigma){
  x = SGAseq(x)
  mat = matrix(NA, length(x),length(x));
  for(i in 1:length(x)){
    for(j in 1:length(x)){
      n1 = x[i];
      n2 = x[j];
      mat[i,j] = exp(-(n1^2+n2^2)/(2*sigma^2));
    }
  }
  mat = mat/sum(mat)
  return(mat)
}


# Average filter
faverage <- function(size){
  x = 1/(size*size)
  ret = matrix(rep(x, size*size), size,size)
  return(ret)
}

# Helper function for fgaussian - given some value x, returns a gradient array begining with 0 on the inside and increasing outwards. Example: x = 7 returns [3,2,1,0,1,2,3] 
# Inputs:
#	x = number of elements in the returned array
# The seq function was edited from the original
SGAseq <- function(x){
  n = x;
  x = c(1:x)
  if(n%%2){
    rhs = x[1:floor(length(x)/2)];
    lhs = rev(rhs);
    return(c(lhs,0,rhs))
  }else{
    rhs = x[1:floor(length(x)/2)] - 0.5;
    lhs = rev(rhs);
    return(c(lhs,rhs))
  }
}

# Applies a filter to a matrix: see imfilter (matlab) with replicate option
# Inputs:
#	mat = matrix to which the filter is applied
# filter = a square matrix filter to be applied to the matrix 
applyfilter <- function(mat, filter, padding_type = 'zeros'){
  mat2 = mat
  fs = dim(filter);
  if(fs[1] != fs[2])
    stop('Filter must be a square matrix')
  if(fs[1] %% 2 == 0)
    stop('Filter dimensions must be odd')
  if(fs[1] == 1)
    stop('Filter dimensions must be greater than one')
  
  x = fs[1];
  a = (x-1)/2;
  
  s = dim(mat2)
  r = matrix(0, s[1], s[2])
  
  start = 1+a;
  end_1 = s[1]+a;
  end_2 = s[2]+a;
  
  mat2 = padmatrix(mat, a, padding_type)
  
  for(i in start:end_1){
    for(j in start:end_2){
      temp = mat2[(i-a):(i+a), (j-a):(j+a)] * filter;
      r[(i-a),(j-a)] = sum(temp)
    }
  }
  return(r)
}

# Applies a filter to a matrix: see imfilter (matlab) with replicate option
# Inputs:
#	mat = matrix to which the filter is applied
# dim = number of rows/cols of window
medianfilter2d <- function(mat, dim, padding_type = 'zeros'){
  mat2 = mat
  fs = c()
  fs[1] = dim
  fs[2] = dim
  
  if(fs[1] != fs[2])
    stop('Filter must be a square matrix')
  if(fs[1] %% 2 == 0)
    stop('Filter dimensions must be odd')
  if(fs[1] == 1)
    stop('Filter dimensions must be greater than one')
  
  x = fs[1];
  a = (x-1)/2;
  
  s = dim(mat2)
  r = matrix(0, s[1], s[2])
  
  start = 1+a;
  end_1 = s[1]+a;
  end_2 = s[2]+a;
  
  mat2 = padmatrix(mat, a, padding_type)
  
  for(i in start:end_1){
    for(j in start:end_2){
      temp = mat2[(i-a):(i+a), (j-a):(j+a)];
      r[(i-a),(j-a)] = median(temp)
    }
  }
  return(r)
}

# Adds a padding to some matrix mat such that the padding is equal to the value of the nearest cell
# Inputs:
#	mat = matrix to which the padding is added
#	lvl = number of levels (rows/columns) of padding to be added
#	padding = type of padding on the matrix, zero will put zeros as borders, replicate will put the value of the nearest cell
padmatrix <- function(mat, lvl, padding){
  s = dim(mat);
  row_up = mat[1,]
  row_down = mat[s[1],]
  
  if(padding == 'zeros'){
    row_up = rep(0, length(row_up))
    row_down = rep(0, length(row_down))
  }
  #Add upper replicates
  ret = t(matrix(rep(row_up, lvl), length(as.vector(row_up))))
  #Add matrix itself
  ret = rbind(ret, mat)
  #Add lower replicates
  ret = rbind(ret, t(matrix(rep(row_down, lvl), length(as.vector(row_down)))))
  
  #Add columns
  s = dim(ret);
  col_left = ret[,1]
  col_right = ret[,s[2]]
  
  if(padding == 'zeros'){
    col_left = rep(0, length(col_left))
    col_right = rep(0, length(col_right))
  }
  
  #Add left columns
  ret2 = matrix(rep(col_left, lvl), length(as.vector(col_left)))
  #Add matrix itself
  ret2 = cbind(ret2, ret)
  #Add right columns
  ret2 = cbind(ret2, matrix(rep(col_right, lvl), length(as.vector(col_right))))
  
  #return 
  return(ret2)
}

```


# Experiment Description

The screen is conducted in 1536-colony format with 4 replicates per query in a 2x2 group.

```{r Experiment description, echo = FALSE}
ExpCondition <- data.frame(rep(c("Query 1"), each = 2),
                            rep(c("Query 1"), each = 2),
                            rep(c("Query 2"), times = 2),
                            rep(c("Query 2"), times = 2))
names(ExpCondition) <- c("", "", "", "")

knitr::kable(ExpCondition, col.names = NULL,
             caption = paste("Query layout")) %>%
  kable_styling(c("bordered"), full_width = FALSE,
                position = "left", font_size = 16)

```

All plates contain dummy strains for the 4 outermost rows and columns of the 1536-colony format, which will not be used for analysis.

Construction of the library was done in 384-format in July of the year 2023. After selection of haploid double mutants, induction of the C-SWAT library was made in Gal/Raf medium and the plasmid further expelled in 5-FOA plates. To conclude, the colonies were pinned onto recovery plates (hyg) for the selection of the new double mutants and allowed to grow for 2 days and photographed.

From this set of plates, the colonies were replicated from 384 to 1536-array format. This 1535-array was repinned one more time to take into account differences in growth that can occurs for the first time that it is pinned in 1536-array format. To transform between 384 to 1536, the same single replicate is plate for times, forming a square of the same replicate. Then, the final assembly plate is replicated onto control plate (without IAA) and with 1um IAA. Two experiments were performed with this original 1536-array plate, making them not fully independent. The data analyses here comes from a experiment performed at the 17-08-2023

Since the growth was slower for the colonies in the DDA drugs (for the HU and the MMS plates), images were acquired on day 1 and day 2. the detection software cannot identify correctly the colonies on the CPT plates day 2, since they are clearly overgrown. Nevertheless, for all the other conditions, there is data obtained from day 1 and day 2.

The labels used for this analyses are: 
- prePin - images of the library in the 1536-array format to take into account the missing strains from the library.
- IAA_d1 - images from the IAA plate, day 1
- IAA_d2 - images from the IAA plate, day 2
- ctrl_d1 - control images, day 1
- ctrl_d1 - control images, day 1
- MMS_d1 - images from the MMS plates without auxin, day 1
- MMS_d2 - images from the MMS plates without auxin, day 2
- MMS_IAA_d1 - images from the MMS plates with auxin, day 1
- MMS_IAA_d2 - images from the MMS plates with auxin, day 2
- HU_d1 - images from the HU plates without auxin, day 1
- HU_d2 - images from the HU plates without auxin, day 2
- HU_IAA_d1 - images from the HU plates with auxin, day 1
- HU_IAA_d2 - images from the HU plates with auxin, day 2
- CPT_d1 - images from the CPT plates without auxin, day 1
- CPT_IAA_d1 - images from the CPT plates with auxin, day 1

For the analyses of the data, for the Essential Genes screen, only replicate 1 and 2 will be used.

# Data Processing

The analysis begins with loading the colony size data obtained from image segmentation done in the pre-analysis markdown file.

```{r Data load 1}
# Load the colony size data from photograph segmentation
load("dataTableRaw.rda")
head(df)

# Modify the table into a long form for simpler analysis.
df_mod <- df %>%
  select(-contains("circularity")) %>%
  pivot_longer(26:39, names_to = "plate_type", values_to = "size") %>%
  mutate(plate_type = substr(plate_type, 5, length(plate_type)),
         ori_plate_type = plate_type,
         day = substring(plate_type, nchar(plate_type), nchar(plate_type)),
         day = as.numeric(day),
         plate_type = ifelse(is.na(day), paste0(plate_type, "1"), plate_type),
         day = ifelse(is.na(day),1,day),
         plate_type = substring(plate_type, 1, nchar(plate_type)-1),
         row = alphabet1536_rev[row_1536],
         col = col_1536) %>% 
  select(row, col, 1:29)

```


## Remove Border Colonies and Mark Missing Positions

First, we look at the distribution of the colony sizes of the complete dataset for the different stages/treatments. 

```{r Border n empty spot filtering 1, fig.width = 16, fig.height = 10}
binvalue <- 200

ggplot(data = df_mod %>% group_by(plate_96, well_96) %>% summarise_if(is.numeric, mean, na.rm = T)) + 
  geom_histogram(aes(size), bins = binvalue) +
  scale_x_continuous(breaks = seq(-100, 2000, by = 100)) +
  labs(x = "Colony Size (Raw)",
       title = "Raw colony size (recovery plate 384-array)")

ggplot(data = df_mod) + 
  geom_histogram(aes(size), bins = binvalue) +
  facet_wrap(vars(plate_type, day), scales = "free_y") +
  scale_x_continuous(breaks = seq(-100, 2000, by = 100)) +
  labs(x = "Colony Size (Raw)",
       title = "Raw colony size",
       subtitle = "Grouped by plate type/stage")

```

The colony sizes which are 0 are changed to NA as they are already known to be empty positions. This change is based on the prePin data and will be applied to the whole dataset so, if there is growth occurring in that position during the experiment, it is not quantified as a real colony. Then, border colonies are marked, and the colony sizes are also set to NA.

```{r Border n empty spot filtering 2}
# Modify the border colonies table
BorderColonies2 <- BorderColonies %>%
  mutate(IsBorder = TRUE)

# Combining the data table with the border colonies list to mark border and
# non-border colonies
df_woBorder <- left_join(df_mod, BorderColonies2,
                                     by = "well")
df_woBorder$IsBorder[is.na(df_woBorder$IsBorder)] <- FALSE

# Marking empty positions from the crossing
df_woBorder_2 <- df_woBorder %>%
  mutate(IsEmpty_Hyg = sizeHyg == 0) %>%
  # Set the empty positions size as NA
  mutate(size = ifelse(IsEmpty_Hyg, NA_integer_, size)) %>%
  # Set the border colonies size as NA
  mutate(size = ifelse(IsBorder, NA_integer_, size))

```

The raw colony sizes are shown again below with the empty positions and border colonies removed.

```{r Border n empty spot filtering 3, fig.width = 16, fig.height = 10}
ggplot(data = df_woBorder_2 %>% group_by(plate_96, well_96) %>% summarise_if(is.numeric, mean, na.rm = T)) + 
  geom_histogram(aes(sizeHyg), bins = binvalue) +
  scale_x_continuous(breaks = seq(-100, 2000, by = 100)) +
  labs(x = "Colony Size (Raw)",
       title = "Raw colony size (recovery plate 384-array)",
       subtitle = "Empty positions and border colonies are removed.")

ggplot(data = df_woBorder_2) + 
  geom_histogram(aes(size), bins = binvalue) +
  facet_wrap(vars(plate_type,day), scales = "free_y") +
  scale_x_continuous(breaks = seq(-100, 2000, by = 100)) +
  labs(x = "Colony Size (Raw)",
       title = "Raw colony size",
       subtitle = paste0("Grouped by plate type/stage",
                         "\nEmpty positions and border colonies are removed."))

```

Next, we look at the colony sizes by plate to see if there are any strong plate effects.

```{r RawData visualisation 1, fig.height = 22}
ggplot(data = df_woBorder_2 %>% group_by(plate, plate_96, well_96) %>% summarise_if(is.numeric, mean, na.rm = T)) +
  geom_boxplot(aes(plate, sizeHyg)) +
  theme(axis.text.x = element_text(angle = -45)) +
  labs(x = "Plate",
       y = "Colony Size (Raw)",
       title = "Raw colony size by plate (recovery plate 384-array)",
       subtitle = "Empty positions and border colonies are removed.")

ggplot(data = df_woBorder_2) +
  geom_boxplot(aes(plate, size)) +
  facet_wrap(vars(plate_type, day), scales = "free_y") +
  theme(axis.text.x = element_text(angle = -45)) +
  labs(x = "Plate",
       y = "Colony Size (Raw)",
       title = "Raw colony size by plate (final assembly plate)",
       subtitle = paste0("Grouped by plate type/stage",
                         "\nEmpty positions and border colonies are removed."))

```

This analysis also shows that the average size varies from plate to plate but without any plates having a very large difference.The plates with the auxin show a bigger tendency to the small size colonies, as expected.

Lastly, we examine the data for spatial effects. The colony sizes for several plates are shown as heatmaps.

```{r RawData visualisation 3, fig.height = 20}
#Library
grid.arrange(
  heatplot(data_table = df_woBorder_2, plate_number = 2, fill_col = "sizeHyg", source_type = "recovery \n384-array"),
  heatplot(data_table = df_woBorder_2, plate_number = 10, fill_col = "sizeHyg", source_type = "recovery \n384-array"),
  heatplot(data_table = df_woBorder_2, plate_number = 18, fill_col = "sizeHyg", source_type = "recovery \n384-array"),
  heatplot(data_table = df_woBorder_2, plate_number = 23, fill_col = "sizeHyg", source_type = "recovery \n384-array"),
  ncol = 2)

#Control
grid.arrange(
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "ctrl_d1"),
           plate_number = 2, fill_col = "size", source_type = "ctrl_d1", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "ctrl_d1"),
           plate_number = 10, fill_col = "size", source_type = "ctrl_d1", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "ctrl_d1"),
           plate_number = 18, fill_col = "size", source_type = "ctrl_d1", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "ctrl_d1"),
           plate_number = 23, fill_col = "size", source_type = "ctrl_d1", upperlimit = 500, midpoint = 250),
  ncol = 2)

grid.arrange(
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "ctrl_d2"),
           plate_number = 2, fill_col = "size", source_type = "ctrl_d2", upperlimit = 800, midpoint = 400),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "ctrl_d2"),
           plate_number = 10, fill_col = "size", source_type = "ctrl_d2", upperlimit = 800, midpoint = 400),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "ctrl_d2"),
           plate_number = 18, fill_col = "size", source_type = "ctrl_d2", upperlimit = 800, midpoint = 400),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "ctrl_d2"),
           plate_number = 23, fill_col = "size", source_type = "ctrl_d2", upperlimit = 800, midpoint = 400),
  ncol = 2)


#IAA
grid.arrange(
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "IAA_d1"),
           plate_number = 2, fill_col = "size", source_type = "IAA_d1", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "IAA_d1"),
           plate_number = 10, fill_col = "size", source_type = "IAA_d1", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "IAA_d1"),
           plate_number = 18, fill_col = "size", source_type = "IAA_d1", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "IAA_d1"),
           plate_number = 23, fill_col = "size", source_type = "IAA_d1", upperlimit = 500, midpoint = 250),
  ncol = 2)

grid.arrange(
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "IAA_d2"),
           plate_number = 2, fill_col = "size", source_type = "IAA_d2", upperlimit = 800, midpoint = 400),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "IAA_d2"),
           plate_number = 10, fill_col = "size", source_type = "IAA_d2", upperlimit = 800, midpoint = 400),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "IAA_d2"),
           plate_number = 18, fill_col = "size", source_type = "IAA_d2", upperlimit = 800, midpoint = 400),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "IAA_d2"),
           plate_number = 23, fill_col = "size", source_type = "IAA_d2", upperlimit = 800, midpoint = 400),
  ncol = 2)

#HU
grid.arrange(
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "HU_d1"),
           plate_number = 2, fill_col = "size", source_type = "HU_d1", upperlimit = 300, midpoint = 150),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "HU_d1"),
           plate_number = 10, fill_col = "size", source_type = "HU_d1", upperlimit = 300, midpoint = 150),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "HU_d1"),
           plate_number = 18, fill_col = "size", source_type = "HU_d1", upperlimit = 300, midpoint = 150),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "HU_d1"),
           plate_number = 23, fill_col = "size", source_type = "HU_d1", upperlimit = 300, midpoint = 150),
  ncol = 2)

grid.arrange(
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "HU_d2"),
           plate_number = 2, fill_col = "size", source_type = "HU_d2", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "HU_d2"),
           plate_number = 10, fill_col = "size", source_type = "HU_d2", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "HU_d2"),
           plate_number = 18, fill_col = "size", source_type = "HU_d2", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "HU_d2"),
           plate_number = 23, fill_col = "size", source_type = "HU_d2", upperlimit = 500, midpoint = 250),
  ncol = 2)


#HU_IAA
grid.arrange(
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "HU_IAA_d1"),
           plate_number = 2, fill_col = "size", source_type = "HU_IAA_d1", upperlimit = 300, midpoint = 150),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "HU_IAA_d1"),
           plate_number = 10, fill_col = "size", source_type = "HU_IAA_d1", upperlimit = 300, midpoint = 150),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "HU_IAA_d1"),
           plate_number = 18, fill_col = "size", source_type = "HU_IAA_d1", upperlimit = 300, midpoint = 150),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "HU_IAA_d1"),
           plate_number = 23, fill_col = "size", source_type = "HU_IAA_d1", upperlimit = 300, midpoint = 150),
  ncol = 2)

grid.arrange(
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "HU_IAA_d2"),
           plate_number = 2, fill_col = "size", source_type = "HU_IAA_d2", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "HU_IAA_d2"),
           plate_number = 10, fill_col = "size", source_type = "HU_IAA_d2", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "HU_IAA_d2"),
           plate_number = 18, fill_col = "size", source_type = "HU_IAA_d2", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "HU_IAA_d2"),
           plate_number = 23, fill_col = "size", source_type = "HU_IAA_d2", upperlimit = 500, midpoint = 250),
  ncol = 2)


#CPT
grid.arrange(
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "CPT_d1"),
           plate_number = 2, fill_col = "size", source_type = "CPT_d1", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "CPT_d1"),
           plate_number = 10, fill_col = "size", source_type = "CPT_d1", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "CPT_d1"),
           plate_number = 18, fill_col = "size", source_type = "CPT_d1", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "CPT_d1"),
           plate_number = 23, fill_col = "size", source_type = "CPT_d1", upperlimit = 500, midpoint = 250),
  ncol = 2)

#CPT_IAA
grid.arrange(
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "CPT_IAA_d1"),
           plate_number = 2, fill_col = "size", source_type = "CPT_IAA_d1", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "CPT_IAA_d1"),
           plate_number = 10, fill_col = "size", source_type = "CPT_IAA_d1", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "CPT_IAA_d1"),
           plate_number = 18, fill_col = "size", source_type = "CPT_IAA_d1", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "CPT_IAA_d1"),
           plate_number = 23, fill_col = "size", source_type = "CPT_IAA_d1", upperlimit = 500, midpoint = 250),
  ncol = 2)


#MMS
grid.arrange(
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "MMS_d1"),
           plate_number = 2, fill_col = "size", source_type = "MMS_d1", upperlimit = 300, midpoint = 150),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "MMS_d1"),
           plate_number = 10, fill_col = "size", source_type = "MMS_d1", upperlimit = 300, midpoint = 150),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "MMS_d1"),
           plate_number = 18, fill_col = "size", source_type = "MMS_d1", upperlimit = 300, midpoint = 150),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "MMS_d1"),
           plate_number = 23, fill_col = "size", source_type = "MMS_d1", upperlimit = 300, midpoint = 150),
  ncol = 2)

grid.arrange(
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "MMS_d2"),
           plate_number = 2, fill_col = "size", source_type = "MMS_d2", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "MMS_d2"),
           plate_number = 10, fill_col = "size", source_type = "MMS_d2", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "MMS_d2"),
           plate_number = 18, fill_col = "size", source_type = "MMS_d2", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "MMS_d2"),
           plate_number = 23, fill_col = "size", source_type = "MMS_d2", upperlimit = 500, midpoint = 250),
  ncol = 2)

#MMS_IAA
grid.arrange(
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "MMS_IAA_d1"),
           plate_number = 2, fill_col = "size", source_type = "MMS_IAA_d1", upperlimit = 300, midpoint = 150),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "MMS_IAA_d1"),
           plate_number = 10, fill_col = "size", source_type = "MMS_IAA_d1", upperlimit = 300, midpoint = 150),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "MMS_IAA_d1"),
           plate_number = 18, fill_col = "size", source_type = "MMS_IAA_d1", upperlimit = 300, midpoint = 150),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "MMS_IAA_d1"),
           plate_number = 23, fill_col = "size", source_type = "MMS_IAA_d1", upperlimit = 300, midpoint = 150),
  ncol = 2)

grid.arrange(
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "MMS_IAA_d2"),
           plate_number = 2, fill_col = "size", source_type = "MMS_IAA_d2", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "MMS_IAA_d2"),
           plate_number = 10, fill_col = "size", source_type = "MMS_IAA_d2", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "MMS_IAA_d2"),
           plate_number = 18, fill_col = "size", source_type = "MMS_IAA_d2", upperlimit = 500, midpoint = 250),
  heatplot(data_table = df_woBorder_2 %>% filter(ori_plate_type == "MMS_IAA_d2"),
           plate_number = 23, fill_col = "size", source_type = "MMS_IAA_d2", upperlimit = 500, midpoint = 250),
  ncol = 2)



```


## Data Correction and Normalization

Here we use SGA Tools (Omar Wagih et al., 2013) to correct the data for plate and spatial effects as follows:

1) plateNormalization 1 (pnorm): Normalises colony sizes to the plate median per plate.

2) spatialNormalization (snorm): Normalizes pnorm colony sizes on each plate using a gaussian filter to normalize for any gradient effect on the plate via median smoothing.

3) plateNormalization 2 (pnorm2): Re-normalises rcnorm colony sizes to the plate median of all plates.


Row and Column normalization was not performed due to overcompensation of "normal size"colonies in rows and column with a lot of hits, that is, small colonies.

### Data Normalization

The SGA Tools normalizeSGA function is executed. No median normalization is done beforehand since the strains are not crossed with different query types.
SGA normalization is not done for the hygromycin recovery step since that is only to determine empty positions (i.e. failed crosses).

```{r Normalization setup}
# Plates description
nPlates <- 24
nROW <- 32
nCOL <- 48

# Overall experiment plate median is set to be able to compare between different
# conditions/plates.
KOPM <- median(df_woBorder_2$size, na.rm = T)

```

The normalization is done for `r paste(nPlates)` plates, with `r paste(nROW)` rows and `r paste(nCOL)` columns in a `r paste(nROW*nCOL)` format.

```{r Data normalization, results = 'hide'}
# Normalization of the data based on median adjusted size
DataInput <- df_woBorder_2
PlateInput <- unique(df_woBorder_2$ori_plate_type)

# Temporary table to hold the data for normalization with just the column names
retA <- data.frame(DataInput[0, ])

# Normalize the remaining plates.
  for(pt in PlateInput){
    for(i in 1:nPlates){
      print(paste0("plate=",i," platetype=",pt))
      
      retB <- DataInput %>% filter(plate_1536 == i, ori_plate_type == pt)
      
      retC <- normalizeSGA(plate.data = retB, overall.plate.median = KOPM,
                           field.to.normalize = "size")
      
      retA <- rbind(retA, retC)
    }
  }




#To calculate the library median using only the values between 0.4 and 0.8 of the size distribution.
vals = sort(retA$pnorm2)
length = length(vals)
lower = 0.4
upper = 0.8



# Return the normalized data from the temporary table to a permanent table.
df_normalized <- retA %>%
  group_by(plate, ori_plate_type, day) %>%
  # Adjust the values according to the median of the plate
  mutate(platemedian2 = median(vals[round(lower*length):round(upper*length)], na.rm = T),
         pnorm3 = pnorm2/platemedian2) %>%
  ungroup() %>%
  do({
    tempA <- .
    # Change the NAs to zero for the jackknife function.
    tempA$pnorm3[is.na(tempA$pnorm3)] <- 0
    tempB <- tempA %>%
      # Performing jackknife marking here. It checks for colonies that contribute
      # more than 90% of total variance in their replicates and marks as TRUE
      group_by(plate, ori_plate_type, ORF) %>%
      mutate(JK = jackknife(pnorm3, theta)$jack.values,
             total.var = var(pnorm3, na.rm=T) * (length(pnorm3)-1),
             jk.var =  (JK^2) * (length(JK)-2),
             JK.TRUE = (total.var - jk.var) > (0.9*total.var)) %>%
      ungroup()
    tempB
  }) %>%
  ungroup()

save(df_normalized, file = "df_normalized")

```


### Illustrating Normalization Outcome

Colony sizes are shown here by plate with boxplots to illustrate how the normalization affects the data for each step.

```{r Post-normalization boxplot, fig.height = 24}


ggplot(data = df_normalized) + 
  geom_violin(aes(as.factor(plate), size)) + 
  facet_wrap(vars(plate_type, day)) +
  labs(x = "Plate", y = "Colony Size", 
       title = "Raw colony size") +
  theme(axis.text.x = element_text(angle = -45))

ggplot(data = df_normalized) + 
  geom_boxplot(aes(as.factor(plate), pnorm)) +
  facet_wrap(vars(plate_type, day)) +
  labs(x = "Plate", y = "Colony Size", 
       title = "Colony size (SGA Tools - pnorm)") +
  theme(axis.text.x = element_text(angle = -45))

ggplot(data = df_normalized) + 
  geom_boxplot(aes(as.factor(plate), snorm)) +
  facet_wrap(vars(plate_type, day)) +
  labs(x = "Plate", y = "Colony Size", 
       title = "Colony size (SGA Tools - snorm)") +
  theme(axis.text.x = element_text(angle = -45))

ggplot(data = df_normalized) + 
  geom_boxplot(aes(as.factor(plate), pnorm2)) +
  facet_wrap(vars(plate_type, day)) +
  labs(x = "Plate", y = "Colony Size",
       title = "Colony size (SGA Tools - pnorm2)") +
  theme(axis.text.x = element_text(angle = -45))



```

Some plates are plotted as heatmaps to illustrate the changes made by SGA Tools normalization.

The heatmaps below show the plates raw colony sizes, post-SGA Tools normalization, and the difference made by SGA Tools normalization.

```{r Post-normalization heatmap 1, fig.height = 24}
# Heatmaps
pI <- PlateInput[1]
print(pI)

p_number <- 3
heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "size",
         "raw", upperlimit = 400, midpoint = 200, breakpoints = 100) +
  heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "pnorm2",
           "pnorm2", upperlimit = 400, midpoint = 200, breakpoints = 100) +
  heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "pnorm2 - size",
           "Difference", lowerlimit = -100, upperlimit = 150, midpoint = 0, breakpoints = 100) +
  plot_layout(ncol = 1, nrow = 3)

p_number <- 12
heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "size",
         "raw", upperlimit = 400, midpoint = 200, breakpoints = 100) +
  heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "pnorm2",
           "pnorm2", upperlimit = 400, midpoint = 200, breakpoints = 100) +
  heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "pnorm2 - size",
           "Difference", lowerlimit = -100, upperlimit = 150, midpoint = 0, breakpoints = 100) +
  plot_layout(ncol = 1, nrow = 3)


p_number <- 20
heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "size",
         "raw", upperlimit = 400, midpoint = 200, breakpoints = 100) +
  heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "pnorm2",
           "pnorm2", upperlimit = 400, midpoint = 200, breakpoints = 100) +
  heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "pnorm2 - size",
           "Difference", lowerlimit = -100, upperlimit = 150, midpoint = 0, breakpoints = 100) +
  plot_layout(ncol = 1, nrow = 3)


```


```{r Post-normalization heatmap 3, fig.height = 24}
# Heatmaps
pI <- PlateInput[3]
print(pI)

p_number <- 3
heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "size",
         "raw", upperlimit = 600, midpoint = 300, breakpoints = 200) +
  heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "pnorm2",
           "pnorm2", upperlimit = 500, midpoint = 250, breakpoints = 100) +
  heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "pnorm2 - size",
           "Difference", lowerlimit = -200, upperlimit = 100, midpoint = 0, breakpoints = 100) +
  plot_layout(ncol = 1, nrow = 3)

p_number <- 12
heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "size",
         "raw", upperlimit = 600, midpoint = 300, breakpoints = 200) +
  heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "pnorm2",
           "pnorm2", upperlimit = 500, midpoint = 250, breakpoints = 100) +
  heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "pnorm2 - size",
           "Difference", lowerlimit = -200, upperlimit = 100, midpoint = 0, breakpoints = 100) +
  plot_layout(ncol = 1, nrow = 3)


p_number <- 20
heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "size",
         "raw", upperlimit = 600, midpoint = 300, breakpoints = 200) +
  heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "pnorm2",
           "pnorm2", upperlimit = 500, midpoint = 250, breakpoints = 100) +
  heatplot(df_normalized %>% filter(ori_plate_type == pI), p_number, "pnorm2 - size",
           "Difference", lowerlimit = -200, upperlimit = 100, midpoint = 0, breakpoints = 100) +
  plot_layout(ncol = 1, nrow = 3)

```


With the data normalized, the whole data frame is simplified for further analysis.

```{r Normalization end}
# Simplify the normalized data table
# Remove the empty border rows and remove locations where the ORF was not present in the final recovery step.
df_norm_simplified <- df_normalized %>%
  select(plate, well, ORF, gene, sizeHyg, plate_type, ori_plate_type, size, day,
         IsBorder, IsEmpty_Hyg, JK.TRUE, pnorm3) %>%
  filter(!IsBorder, !IsEmpty_Hyg)

ggplot(data = df_norm_simplified) + 
  geom_boxplot(aes(as.factor(plate), pnorm3)) +
  facet_wrap(vars(plate_type, day)) +
  labs(x = "Plate", y = "Colony Size", 
       title = "Colony size (Normalized by plate median)") +
  theme(axis.text.x = element_text(angle = -45))


```


# Data Analysis


In this section, the difference between each ORF and the median per plate adjusting for the deviation per plate is calculated as the Z-score. The colonies that contribute to more than 90% of total variance in their replicates are not used for any calculations.

A t-test is then calculated to determine the significance of this difference. The p-values are corrected for multiple testing using the Benjamini-Hochberg method. The results are shown as volcano plots with the significant hits listed in the tables below each plot.

```{r Data analysis 1 - Z-score}

#To restrict the calculations between the values between 0.4 and 0.8 of the size distribution.
vals = sort(df_norm_simplified$pnorm3)
length = length(vals)
lower = 0.4
upper = 0.8

# Dividing the colony sizes by the median of all colonies for that query
df_norm_platevalues <- df_norm_simplified %>%
  group_by(plate, ori_plate_type) %>%
  summarise(plate_median1 = median(vals[round(lower*length):round(upper*length)], na.rm = T),
            plate_mad1 = mad(vals[round(lower*length):round(upper*length)], na.rm = T)) %>%
  ungroup()

# Changing NA positions to zero for T-test calculations.
df_norm_2 <- df_norm_simplified %>%
  mutate(pnorm3 = ifelse(is.na(pnorm3), 0, pnorm3))

# Calculating the z-score
df_norm_3 <- df_norm_2 %>%
  filter(!JK.TRUE) %>%
  left_join(., df_norm_platevalues, by = c("plate", "ori_plate_type")) %>%
  mutate(delta_size_score = (pnorm3 - plate_median1) / plate_mad1)

#Remove values that are zero
tmp <- df_norm_3[df_norm_3$size == 0,]
tmp <- tmp %>% filter(ori_plate_type == "ctrl_d1")

df_norm_3 <- anti_join(df_norm_3, tmp, by = "ORF")
df_norm_3  <- df_norm_3  %>% drop_na(ORF)

```

After calculating the z-score, the distribution of each plate/stage is shown below. It was also calculated a distribution for the Z-score calculated for the first and second replicate together (second graphic). From now on, everytime there is only one graphic depicted for "IAA" and "control" is with both replicate one and two together.

```{r Data analysis 2 - Z-score}
ggplot() +
  geom_histogram(data = df_norm_3, aes(delta_size_score), bins = 200) +
  facet_wrap(vars(ori_plate_type)) +
  labs(x = "Z-score",
       subtitle = "Z-score = (normalised size - plate median) / plate MAD")

```

From the graphs above, we can already see that treatment with IAA leads to a decrease in fitness for some ORFs and has a stronger effect than the control plate.


## T-tests

The t-test compares the mean value of the sample (the 4 replicates of each ORF) against the population (All ORFs on the same plate type/condition).

This is essentially a one sample T-test because there is technically no WT counterpart for comparison against. Furthermore, with all the corrections done, the mean of the population is zero (as seen in the plots above).

```{r Data analysis 3 - Z-score}
df_final <- df_norm_3 %>% 
  group_by(plate, ori_plate_type, ORF, gene) %>%
  filter(n() > 1) %>%
  summarise(delta_size_score_median = median(delta_size_score, na.rm = T),
            norm_size_median = median(pnorm3, na.rm = T),
            pvaluesize = tryCatch({t.test(delta_size_score)$p.value}, error = function(e){NA}),
            df_size = tryCatch({t.test(delta_size_score)$parameter}, error = function(e){NA}),
            norm_pvaluesize = tryCatch({t.test(pnorm3)$p.value}, error = function(e){NA}),
            norm_df_size = tryCatch({t.test(pnorm3)$parameter}, error = function(e){NA})) %>%
  group_by(ori_plate_type) %>%
  mutate(BHsize = p.adjust(pvaluesize, method = "BH"),
         norm_BHsize = p.adjust(norm_pvaluesize, method = "BH")
         ) %>%
  ungroup() 

# To eliminate Repeated ORF
DataInput1 <- df_final
retD <- data.frame(DataInput[0, ])
for(pt in PlateInput){
      
      retB <- DataInput1 %>% filter(ori_plate_type == pt)
      
      retC <- retB[!duplicated(retB$ORF),]
      
      retD <- rbind(retD, retC)

}

df_final <- retD


save(df_final, file = "df_final")
save(df_norm_3, file = "df_norm_3")


```

```{r}
load("df_final")
load("df_norm_3")

```


# Data Visualisation

## Volcano plot

Several thresholds are set here.

```{r Thresholds 1}
# Change these value to the desired threshold. Currently the settings are:

# Z-score threshold
sizeThresLow <- -10

# Quotient Threshold
sizeThresquot <- 0.80

# BH corrected p-value
BHThres <- 0.05

```


After performing the calculations, the volcano plots are shown below. The thresholds applied are: BH corrected p-value < `r paste(BHThres)` with Z-score threshold of `r paste(sizeThresLow)`.

```{r VolcanoPlot - Z-score}
ggplot() + 
  geom_point(data = df_final,
             aes(delta_size_score_median, -log10(BHsize)),
             alpha = 0.2) +
  geom_point(data = df_final %>%
               filter(delta_size_score_median <= sizeThresLow,
                      BHsize < BHThres),
             aes(delta_size_score_median, -log10(BHsize)),
             alpha = 0.2, col = "red") +
  facet_wrap(vars(ori_plate_type)) +
  labs(x = "Z-Score(Colony Size)", y = "-Log10(BH-adjusted p-value)",
       title = "Volcano plot with significant hits highlighted.",
       subtitle = paste("Thresholds applied:",
                        "\nBH-adjusted p-value < ", BHThres,
                        "\nZ-score <", sizeThresLow))

ggplot() + 
  geom_point(data = df_final,
             aes(delta_size_score_median, -log10(BHsize)),
             alpha = 0.2) +
  geom_point(data = df_final %>%
               filter(delta_size_score_median <= sizeThresLow,
                      BHsize < BHThres),
             aes(delta_size_score_median, -log10(BHsize)),
             alpha = 0.2, col = "red") +
  facet_wrap(vars(ori_plate_type)) +
  scale_x_continuous(breaks = seq(-40, 40, by = 5)) +
  scale_y_continuous(limits = c(0, 6), breaks = seq(0, 10, by = 2)) +
  labs(x = "Z-Score(Colony Size)", y = "-Log10(BH-adjusted p-value)",
       title = "Volcano plot with significant hits highlighted.",
       subtitle = paste("Limited Y-axis. Thresholds applied:",
                        "\nBH-adjusted p-value < ", BHThres,
                        "\nZ-score <", sizeThresLow))


```

Based on the volcano plots above, there are several ORFs that already have a growth defect or were small in the assembly step (sizeprePin) and also in the control plates. These ORFs should not be considered for the IAA treatment.

The hits are broken down into individual tables below for further analyses. Although Z-scores were calculated, to compare values between different screens, the calculates values are quotients between the screens.

```{r Outcome of Hits _ Quotient and p_value}

# Library strains
Strains_IAA_d1_quot <- df_norm_3 %>%
  filter(ori_plate_type == "ctrl_d1") %>%
  #Filter
  group_by(plate, ORF, gene) %>%
  filter(n() > 1) %>%
  #Calculate Medians and p-value
  summarise(size_median = median(pnorm3, na.rm = T)) %>%
  drop_na(ORF) %>%
  select(plate, ORF, gene,size_median)
Strains_IAA_d1_quot <- Strains_IAA_d1_quot[!duplicated(Strains_IAA_d1_quot$ORF),]

#Viability screen
Viability_Screen <- df_norm_3 %>%
  # Separate in two tables
  do ({
    tmp <- subset(., ori_plate_type == "IAA_d1") %>% select(-ori_plate_type)
    tmp2 <- subset(., ori_plate_type == "ctrl_d1") %>% select(-ori_plate_type)
    full_join(tmp, tmp2, by = c("plate", "ORF", "gene", "well"),
              suffix = c("_IAA", "_ctrl"))
  }) %>%
  #Filter
  group_by(plate, ORF, gene) %>%
  filter(n() > 1) %>%
  #Calculate Medians and p-value
  summarise(size_median_IAA = median(pnorm3_IAA, na.rm = T),
            size_median_ctrl = median(pnorm3_ctrl, na.rm = T),
            pvaluesize = tryCatch({t.test(x = pnorm3_IAA, y = pnorm3_ctrl, paired = FALSE)$p.value}, error = function(e){NA}),
            df_size = tryCatch({t.test(x = pnorm3_IAA, y = pnorm3_ctrl, paired = FALSE)$parameter}, error = function(e){NA})) %>%
  #Adjust p-value
  mutate(BHsize = p.adjust(pvaluesize, method = "BH")) %>%
  #Calculate quotients
  mutate(delta_size_quot = size_median_IAA/size_median_ctrl) %>%
  drop_na(ORF) %>%
  select(plate, ORF, gene,size_median_IAA,size_median_ctrl, delta_size_quot, BHsize)
Viability_Screen <- Viability_Screen[!duplicated(Viability_Screen$ORF),]

# Hits considering of the p-value
Hits_IAA_d1_quot <- df_norm_3 %>%
  # Separate in two tables
  do ({
    tmp <- subset(., ori_plate_type == "IAA_d1") %>% select(-ori_plate_type)
    tmp2 <- subset(., ori_plate_type == "ctrl_d1") %>% select(-ori_plate_type)
    full_join(tmp, tmp2, by = c("plate", "ORF", "gene", "well"),
              suffix = c("_IAA", "_ctrl"))
  }) %>%
  #Filter
  group_by(plate, ORF, gene) %>%
  filter(n() > 1) %>%
  #Calculate Medians and p-value
  summarise(size_median_IAA = median(pnorm3_IAA, na.rm = T),
            size_median_ctrl = median(pnorm3_ctrl, na.rm = T),
            pvaluesize = tryCatch({t.test(x = pnorm3_IAA, y = pnorm3_ctrl, paired = FALSE)$p.value}, error = function(e){NA}),
            df_size = tryCatch({t.test(x = pnorm3_IAA, y = pnorm3_ctrl, paired = FALSE)$parameter}, error = function(e){NA})) %>%
  #Adjust p-value
  mutate(BHsize = p.adjust(pvaluesize, method = "BH")) %>%
  #Calculate quotients
  mutate(delta_size_quot = size_median_IAA/size_median_ctrl) %>%
  filter(delta_size_quot <= sizeThresquot,
         BHsize < BHThres) %>%
  drop_na(ORF) %>%
  select(plate, ORF, gene,size_median_IAA,size_median_ctrl, delta_size_quot, BHsize)
Hits_IAA_d1_quot <- Hits_IAA_d1_quot[!duplicated(Hits_IAA_d1_quot$ORF),]



Hits_CPT_IAA_d1_quot <- df_norm_3 %>%
  # Separate in two tables
  do ({
    tmp <- subset(., ori_plate_type == "CPT_IAA_d1") %>% select(-ori_plate_type)
    tmp2 <- subset(., ori_plate_type == "CPT_d1") %>% select(-ori_plate_type)
    tmp3 <- full_join(tmp, tmp2, by = c("plate", "ORF", "gene", "well"),
              suffix = c("_CPT_IAA", "_CPT"))
    tmp4 <- subset(., ori_plate_type == "IAA_d1") %>% select(-ori_plate_type)
    full_join(tmp3,tmp4, by = c("plate", "ORF", "gene", "well"))
  }) %>%
  #Filter
  group_by(plate, ORF, gene) %>%
  filter(n() > 1) %>%
  #Calculate Medians and p-value
  summarise(size_median_CPT_IAA = median(pnorm3_CPT_IAA, na.rm = T),
            size_median_CPT = median(pnorm3_CPT, na.rm = T),
            size_median_IAA = median(pnorm3, na.rm = T),
            pvaluesize_CPT = tryCatch({t.test(x = pnorm3_CPT_IAA, y = pnorm3_CPT, paired = FALSE)$p.value}, error = function(e){NA}),
            pvaluesize_IAA = tryCatch({t.test(x = pnorm3_CPT_IAA, y = pnorm3, paired = FALSE)$p.value}, error = function(e){NA}),
            df_size_CPT = tryCatch({t.test(x = pnorm3_CPT_IAA, y = pnorm3_CPT, paired = FALSE)$parameter}, error = function(e){NA}),
            df_size_IAA = tryCatch({t.test(x = pnorm3_CPT_IAA, y = pnorm3, paired = FALSE)$parameter}, error = function(e){NA})) %>%
  #Adjust p-value
  mutate(BHsize_CPT = p.adjust(pvaluesize_CPT, method = "BH"),
         BHsize_IAA = p.adjust(pvaluesize_IAA, method = "BH")) %>%
  #Calculate quotients
  mutate(delta_size_quot_CPT = size_median_CPT_IAA/size_median_CPT,
         delta_size_quot_IAA = size_median_CPT_IAA/size_median_IAA) %>%
  filter(delta_size_quot_CPT <= sizeThresquot,
         delta_size_quot_IAA <= sizeThresquot,
         BHsize_CPT < BHThres,
         BHsize_IAA < BHThres) %>%
  drop_na(ORF) %>%
  select(plate, ORF, gene,size_median_CPT_IAA,size_median_CPT ,size_median_IAA, delta_size_quot_CPT,delta_size_quot_IAA, BHsize_CPT,BHsize_IAA)
Hits_CPT_IAA_d1_quot <- Hits_CPT_IAA_d1_quot[!duplicated(Hits_CPT_IAA_d1_quot$ORF),]



Hits_CPT_d1_quot <- df_norm_3 %>%
  # Separate in two tables
  do ({
    tmp <- subset(., ori_plate_type == "CPT_d1") %>% select(-ori_plate_type)
    tmp2 <- subset(., ori_plate_type == "ctrl_d1") %>% select(-ori_plate_type)
    full_join(tmp, tmp2, by = c("plate", "ORF", "gene", "well"),
              suffix = c("_IAA", "_ctrl"))
  }) %>%
  #Filter
  group_by(plate, ORF, gene) %>%
  filter(n() > 1) %>%
  #Calculate Medians and p-value
  summarise(size_median_IAA = median(pnorm3_IAA, na.rm = T),
            size_median_ctrl = median(pnorm3_ctrl, na.rm = T),
            pvaluesize = tryCatch({t.test(x = pnorm3_IAA, y = pnorm3_ctrl, paired = FALSE)$p.value}, error = function(e){NA}),
            df_size = tryCatch({t.test(x = pnorm3_IAA, y = pnorm3_ctrl, paired = FALSE)$parameter}, error = function(e){NA})) %>%
  #Adjust p-value
  mutate(BHsize = p.adjust(pvaluesize, method = "BH")) %>%
  #Calculate quotients
  mutate(delta_size_quot = size_median_IAA/size_median_ctrl) %>%
  filter(delta_size_quot <= sizeThresquot,
         BHsize < BHThres) %>%
  drop_na(ORF) %>%
  select(plate, ORF, gene,size_median_IAA,size_median_ctrl, delta_size_quot, BHsize)
Hits_CPT_d1_quot <- Hits_CPT_d1_quot[!duplicated(Hits_CPT_d1_quot$ORF),]


Hits_MMS_IAA_d2_quot <- df_norm_3 %>%
  # Separate in two tables
  do ({
    tmp <- subset(., ori_plate_type == "MMS_IAA_d2") %>% select(-ori_plate_type)
    tmp2 <- subset(., ori_plate_type == "MMS_d2") %>% select(-ori_plate_type)
    tmp3 <- full_join(tmp, tmp2, by = c("plate", "ORF", "gene", "well"),
              suffix = c("_MMS_IAA", "_MMS"))
    tmp4 <- subset(., ori_plate_type == "IAA_d1") %>% select(-ori_plate_type)
    full_join(tmp3,tmp4, by = c("plate", "ORF", "gene", "well"))
  }) %>%
  #Filter
  group_by(plate, ORF, gene) %>%
  filter(n() > 1) %>%
  #Calculate Medians and p-value
  summarise(size_median_MMS_IAA = median(pnorm3_MMS_IAA, na.rm = T),
            size_median_MMS = median(pnorm3_MMS, na.rm = T),
            size_median_IAA = median(pnorm3, na.rm = T),
            pvaluesize_MMS = tryCatch({t.test(x = pnorm3_MMS_IAA, y = pnorm3_MMS, paired = FALSE)$p.value}, error = function(e){NA}),
            pvaluesize_IAA = tryCatch({t.test(x = pnorm3_MMS_IAA, y = pnorm3, paired = FALSE)$p.value}, error = function(e){NA}),
            df_size_MMS = tryCatch({t.test(x = pnorm3_MMS_IAA, y = pnorm3_MMS, paired = FALSE)$parameter}, error = function(e){NA}),
            df_size_IAA = tryCatch({t.test(x = pnorm3_MMS_IAA, y = pnorm3, paired = FALSE)$parameter}, error = function(e){NA})) %>%
  #Adjust p-value
  mutate(BHsize_MMS = p.adjust(pvaluesize_MMS, method = "BH"),
         BHsize_IAA = p.adjust(pvaluesize_IAA, method = "BH")) %>%
  #Calculate quotients
  mutate(delta_size_quot_MMS = size_median_MMS_IAA/size_median_MMS,
         delta_size_quot_IAA = size_median_MMS_IAA/size_median_IAA) %>%
  filter(delta_size_quot_MMS <= sizeThresquot,
         delta_size_quot_IAA <= sizeThresquot,
         BHsize_MMS < BHThres,
         BHsize_IAA < BHThres) %>%
  drop_na(ORF) %>%
  select(plate, ORF, gene,size_median_MMS_IAA,size_median_MMS ,size_median_IAA, delta_size_quot_MMS,delta_size_quot_IAA, BHsize_MMS,BHsize_IAA)
Hits_MMS_IAA_d2_quot <- Hits_MMS_IAA_d2_quot[!duplicated(Hits_MMS_IAA_d2_quot$ORF),]


Hits_MMS_d2_quot <- df_norm_3 %>%
  # Separate in two tables
  do ({
    tmp <- subset(., ori_plate_type == "MMS_d2") %>% select(-ori_plate_type)
    tmp2 <- subset(., ori_plate_type == "ctrl_d1") %>% select(-ori_plate_type)
    full_join(tmp, tmp2, by = c("plate", "ORF", "gene", "well"),
              suffix = c("_IAA", "_ctrl"))
  }) %>%
  #Filter
  group_by(plate, ORF, gene) %>%
  filter(n() > 1) %>%
  #Calculate Medians and p-value
  summarise(size_median_IAA = median(pnorm3_IAA, na.rm = T),
            size_median_ctrl = median(pnorm3_ctrl, na.rm = T),
            pvaluesize = tryCatch({t.test(x = pnorm3_IAA, y = pnorm3_ctrl, paired = FALSE)$p.value}, error = function(e){NA}),
            df_size = tryCatch({t.test(x = pnorm3_IAA, y = pnorm3_ctrl, paired = FALSE)$parameter}, error = function(e){NA})) %>%
  #Adjust p-value
  mutate(BHsize = p.adjust(pvaluesize, method = "BH")) %>%
  #Calculate quotients
  mutate(delta_size_quot = size_median_IAA/size_median_ctrl) %>%
  filter(delta_size_quot <= sizeThresquot,
         BHsize < BHThres) %>%
  drop_na(ORF) %>%
  select(plate, ORF, gene,size_median_IAA,size_median_ctrl, delta_size_quot, BHsize)
Hits_MMS_d2_quot <- Hits_MMS_d2_quot[!duplicated(Hits_MMS_d2_quot$ORF),]





Hits_HU_IAA_d2_quot <- df_norm_3 %>%
  # Separate in two tables
  do ({
    tmp <- subset(., ori_plate_type == "HU_IAA_d2") %>% select(-ori_plate_type)
    tmp2 <- subset(., ori_plate_type == "HU_d2") %>% select(-ori_plate_type)
    tmp3 <- full_join(tmp, tmp2, by = c("plate", "ORF", "gene", "well"),
              suffix = c("_HU_IAA", "_HU"))
    tmp4 <- subset(., ori_plate_type == "IAA_d1") %>% select(-ori_plate_type)
    full_join(tmp3,tmp4, by = c("plate", "ORF", "gene", "well"))
  }) %>%
  #Filter
  group_by(plate, ORF, gene) %>%
  filter(n() > 1) %>%
  #Calculate Medians and p-value
  summarise(size_median_HU_IAA = median(pnorm3_HU_IAA, na.rm = T),
            size_median_HU = median(pnorm3_HU, na.rm = T),
            size_median_IAA = median(pnorm3, na.rm = T),
            pvaluesize_HU = tryCatch({t.test(x = pnorm3_HU_IAA, y = pnorm3_HU, paired = FALSE)$p.value}, error = function(e){NA}),
            pvaluesize_IAA = tryCatch({t.test(x = pnorm3_HU_IAA, y = pnorm3, paired = FALSE)$p.value}, error = function(e){NA}),
            df_size_HU = tryCatch({t.test(x = pnorm3_HU_IAA, y = pnorm3_HU, paired = FALSE)$parameter}, error = function(e){NA}),
            df_size_IAA = tryCatch({t.test(x = pnorm3_HU_IAA, y = pnorm3, paired = FALSE)$parameter}, error = function(e){NA})) %>%
  #Adjust p-value
  mutate(BHsize_HU = p.adjust(pvaluesize_HU, method = "BH"),
         BHsize_IAA = p.adjust(pvaluesize_IAA, method = "BH")) %>%
  #Calculate quotients
  mutate(delta_size_quot_HU = size_median_HU_IAA/size_median_HU,
         delta_size_quot_IAA = size_median_HU_IAA/size_median_IAA) %>%
  filter(delta_size_quot_HU <= sizeThresquot,
         delta_size_quot_IAA <= sizeThresquot,
         BHsize_HU < BHThres,
         BHsize_IAA < BHThres) %>%
  drop_na(ORF) %>%
  select(plate, ORF, gene,size_median_HU_IAA,size_median_HU ,size_median_IAA, delta_size_quot_HU,delta_size_quot_IAA, BHsize_HU,BHsize_IAA)
Hits_HU_IAA_d2_quot <- Hits_HU_IAA_d2_quot[!duplicated(Hits_HU_IAA_d2_quot$ORF),]


Hits_HU_d2_quot <- df_norm_3 %>%
  # Separate in two tables
  do ({
    tmp <- subset(., ori_plate_type == "HU_d2") %>% select(-ori_plate_type)
    tmp2 <- subset(., ori_plate_type == "ctrl_d1") %>% select(-ori_plate_type)
    full_join(tmp, tmp2, by = c("plate", "ORF", "gene", "well"),
              suffix = c("_IAA", "_ctrl"))
  }) %>%
  #Filter
  group_by(plate, ORF, gene) %>%
  filter(n() > 1) %>%
  #Calculate Medians and p-value
  summarise(size_median_IAA = median(pnorm3_IAA, na.rm = T),
            size_median_ctrl = median(pnorm3_ctrl, na.rm = T),
            pvaluesize = tryCatch({t.test(x = pnorm3_IAA, y = pnorm3_ctrl, paired = FALSE)$p.value}, error = function(e){NA}),
            df_size = tryCatch({t.test(x = pnorm3_IAA, y = pnorm3_ctrl, paired = FALSE)$parameter}, error = function(e){NA})) %>%
  #Adjust p-value
  mutate(BHsize = p.adjust(pvaluesize, method = "BH")) %>%
  #Calculate quotients
  mutate(delta_size_quot = size_median_IAA/size_median_ctrl) %>%
  filter(delta_size_quot <= sizeThresquot,
         BHsize < BHThres) %>%
  drop_na(ORF) %>%
  select(plate, ORF, gene,size_median_IAA,size_median_ctrl, delta_size_quot, BHsize)
Hits_HU_d2_quot <- Hits_HU_d2_quot[!duplicated(Hits_HU_d2_quot$ORF),]


```


## Scatter plots



```{r}
#Final spread with the calculated values for all the ORFs in all conditions
df_spread_final_1 <- df_norm_3  %>%
  group_by(ORF, ori_plate_type) %>%
  summarise(size = median(pnorm3, na.rm = T)) %>%
  spread(key = ori_plate_type, value = size)
df_spread_final_1 <- df_spread_final_1[!duplicated(df_spread_final_1$ORF),]
df_spread_final_1 <- df_spread_final_1 %>% drop_na()


```

A list of essential genes is loaded in to compare with the hits. The expectation is that most, if not all, of the essential genes should have cause a significant growth defect in the library.

```{r Essential Genes upload}

#Upload of the Essential genes dataset
Ess_Genes <- read.xlsx(xlsxFile = "06_datasets/20200224_Essential_ORFs.xlsx", sheet = "20200224_Essential_ORFs") %>%
  `colnames<-`(c("ORF", colnames(.)[2:6]))
Ess_Genes_inLib <- semi_join(Ess_Genes, df_final, by = "ORF")
Non_Ess_Genes_inLib <- anti_join(df_spread_final_1,Ess_Genes, by = "ORF")


```


```{r Scatter plots with the normalised size}


# Scatter plot

# Scatter plot to observe were the Essential Genes are in terms of fitness defect
Scatter1 <- rbind((anti_join(df_spread_final_1, Ess_Genes_inLib , by = "ORF") %>% mutate(Gene = "Not Essential")), (semi_join(df_spread_final_1, Ess_Genes_inLib , by = "ORF") %>% mutate(Gene = "Essential")))


#Figure SF4b
    
ImS4b <- ggplot(Scatter1) +
      geom_point(aes(ctrl_d1, IAA_d1, color=Gene), alpha = 0.3, size = 2)+
        theme_light(base_size = 20) +
      theme(legend.text = element_text(size = 18),
            legend.title = element_text(size = 16))+ 
      guides(colour = guide_legend(override.aes = list(size=5))) +
        scale_x_continuous(limits = c(0,1.5)) +
      labs(x = "Normalized colony size - control",
           y = "Normalized colony size - 5-Ph-IAA")
print(ImS4b)

ggsave("05_plots/01-Figure_S4b.pdf", 
    height = 8,
    width = 16)
      
ggplot(Scatter1) +
  geom_density(aes(x = ctrl_d1, group = Gene, fill = Gene))

ggplot(Scatter1) +
  geom_density(aes(x = IAA_d1, group = Gene, fill = Gene))
      

# Scatter plot to observe the Hits according to our threshold
Scatter5 <- rbind((anti_join(df_spread_final_1, Hits_IAA_d1_quot , by = "ORF") %>% mutate(ORF = "No hit")), (semi_join(df_spread_final_1, Hits_IAA_d1_quot , by = "ORF") %>% mutate(ORF = "Hit")))


#Figure SF4a
ImS4a <-    ggplot(Scatter5) +
      geom_point(aes(ctrl_d1, IAA_d1, color=ORF), alpha = 0.3, size = 2) +
        theme_light(base_size = 20) +
      theme(legend.text = element_text(size = 18),
            legend.title = element_text(size = 16))+ 
      guides(colour = guide_legend(override.aes = list(size=5))) +
      scale_x_continuous(limits = c(0,1.5)) +
      labs(x = "Normalized colony size - control",
           y = "Normalized colony size - 5-Ph-IAA")
print(ImS4a)

ggsave("05_plots/02-Figure_S4a.pdf", 
    height = 8,
    width = 16)


```


## Comparison with library v1 data

Here we update the dataset obtained from the library v1 to make the comparisons
```{r}

mNG_size <- read.xlsx(xlsxFile = "06_datasets/Library_v1_final_table.xlsx", sheet = "Size") %>%
  select(ORF, size_median_ctrl,size_median_IAA)


df_spread_final_Comp <- left_join(df_spread_final_1, mNG_size, by = "ORF")

df_spread_final_Comp <- df_spread_final_Comp %>% drop_na()


#Figure SF4e

ImS4e <- ggplot(df_spread_final_Comp) +
      geom_point(aes(ctrl_d1, size_median_ctrl), alpha = 0.3, size = 2)+
        theme_light(base_size = 20) +
      theme(legend.text = element_text(size = 18),
            legend.title = element_text(size = 16))+ 
      guides(colour = guide_legend(override.aes = list(size=5))) +
        scale_x_continuous(limits = c(0,1.5)) +
      labs(x = "Normalized colony size - control",
           y = "Normalized colony size - mNG control")

print(ImS4e)

ggsave("05_plots/03-Figure_S4e.pdf", 
    height = 8,
    width = 16)
      
Scoef_ctrl <- cor.test(df_spread_final_Comp$ctrl_d1, df_spread_final_Comp$size_median_ctrl, method ="spearman", exact = FALSE)
Scoef_ctrl


      
ImS4e2 <-  ggplot(df_spread_final_Comp) +
      geom_point(aes(IAA_d1, size_median_IAA), alpha = 0.3, size = 2)+
        theme_light(base_size = 20) +
      theme(legend.text = element_text(size = 18),
            legend.title = element_text(size = 16))+ 
      guides(colour = guide_legend(override.aes = list(size=5))) +
        scale_x_continuous(limits = c(0,1.5)) +
      labs(x = "Normalized colony size - IAA",
           y = "Normalized colony size - mNG IAA")

print(ImS4e2)

ggsave("05_plots/04-Figure_S4e.pdf", 
    height = 8,
    width = 16)
            
Scoef_IAA <- cor.test(df_spread_final_Comp$IAA_d1, df_spread_final_Comp$size_median_IAA, method ="spearman", exact = FALSE)
Scoef_IAA
            
 
              


```



## Protein Localization

We want to see now what is the protein localization of the hits and the ones that were not hits. For this, a database published in the paper https://www.nature.com/articles/nature02026. The dataset was downloaded at 12/09/2022. 

```{r}
Prot_Loc <- read.xlsx(xlsxFile = "06_datasets/20220912_GFPLocalizationLibrary.xlsx", sheet = "allOrfData", sep.names = " ") %>%
  `colnames<-`(c("orfid", colnames(.)[2:32]))
Prot_Loc_inLib <- semi_join(Prot_Loc, df_final, by = "ORF")
Prot_Loc_Ess_inLib <- semi_join(Prot_Loc_inLib, Ess_Genes_inLib, by = "ORF")

```



```{r Protein Localization Essential Genes}

Ess_Hits_quot <- rbind((semi_join(Ess_Genes_inLib, Hits_IAA_d1_quot, by = "ORF") %>% mutate(Category = "Hit")),(anti_join(Ess_Genes_inLib, Hits_IAA_d1_quot, by = "ORF") %>% mutate(Category = "Not Hit")) )

#Attribute each ORF to a cell localization
ORF_Loc_quot <- left_join(Ess_Hits_quot[c("ORF")], Prot_Loc_inLib, by = "ORF", suffix = c(".x",".y"))
ORF_Loc_quot <- as.data.frame(ORF_Loc_quot)

#Remove duplicated rows
ORF_Loc_quot <- ORF_Loc_quot[!duplicated(ORF_Loc_quot$ORF),]
rownames(ORF_Loc_quot) <- ORF_Loc_quot$ORF

#Quantify how many of each cell localization there is per Category
cell_loc_quot <- ORF_Loc_quot[10:length(colnames(ORF_Loc_quot))]
cell_loc_quot <- cell_loc_quot %>% mutate(across(everything(), as.logical))
cell_loc_quot$ORF <- rownames(cell_loc_quot)
cell_loc_quot <- left_join(cell_loc_quot, Ess_Hits_quot[c("ORF", "Category")], by="ORF")
cell_loc_quot <- cell_loc_quot %>% select(-c(ORF)) %>% group_by(Category) %>% summarize_all(sum, na.rm=TRUE) 
colSums(cell_loc_quot %>% select(-c( Category)), na.rm = TRUE)


cell_loc_perc_quot <- adorn_percentages(cell_loc_quot, denominator = "col", na.rm = TRUE)

#Tables
knitr::kable(cell_loc_quot, caption = "Localization of every ORF by Category", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

knitr::kable(cell_loc_perc_quot, caption = "Localization of every ORF by Category in percentage", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

#Transform dataset for plotting
cell_loc_plot_quot <- cell_loc_perc_quot %>% pivot_longer(!Category, names_to = "cellular_comp", values_to = "amount")

#Figure SF4d
ImS4d <- ggplot(data = cell_loc_plot_quot) +
  geom_bar(aes(x = cellular_comp, y = amount,  fill = Category), position = "fill", stat = "identity") +
theme_light(base_size = 20) +
      theme(legend.text = element_text(size = 18),
            legend.title = element_text(size = 16))+ 
      guides(colour = guide_legend(override.aes = list(size=5))) +
  coord_flip() +
  labs(x = "Cellular Components",
       y = "Percentage of ORFs at each Category")

print(ImS4d)

ggsave("05_plots/05-Figure_S4d.pdf", 
    height = 8,
    width = 16)


```

The same result is obtained with this analysis.

The analysis was also performed to the Non Essential dataset.

```{r Protein Localization Non Essential Dataset}

Non_Ess_Hits_quot <- rbind((semi_join(Non_Ess_Genes_inLib, Hits_IAA_d1_quot, by = "ORF") %>% mutate(Category = "Hit")),(anti_join(Non_Ess_Genes_inLib, Hits_IAA_d1_quot, by = "ORF") %>% mutate(Category = "Not Hit")))

#Attribute each ORF to a cell localization
ORF_Loc_quot <- left_join(Non_Ess_Hits_quot[c("ORF")], Prot_Loc_inLib, by = "ORF", suffix = c(".x",".y"))
ORF_Loc_quot <- as.data.frame(ORF_Loc_quot)

#Remove duplicated rows
ORF_Loc_quot <- ORF_Loc_quot[!duplicated(ORF_Loc_quot$ORF),]
rownames(ORF_Loc_quot) <- ORF_Loc_quot$ORF

#Quantify how many of each cell localization there is per Category
cell_loc_quot <- ORF_Loc_quot[10:length(colnames(ORF_Loc_quot))]
cell_loc_quot <- cell_loc_quot %>% mutate(across(everything(), as.logical))
cell_loc_quot$ORF <- rownames(cell_loc_quot)
cell_loc_quot <- left_join(cell_loc_quot, Non_Ess_Hits_quot[c("ORF", "Category")], by="ORF")
cell_loc_quot <- cell_loc_quot %>% select(-c(ORF)) %>% group_by(Category) %>% summarize_all(sum, na.rm=TRUE) 
colSums(cell_loc_quot %>% select(-c( Category)), na.rm = TRUE)


cell_loc_perc_quot <- adorn_percentages(cell_loc_quot, denominator = "col", na.rm = TRUE)

#Tables
knitr::kable(cell_loc_quot, caption = "Localization of every ORF by Category", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

knitr::kable(cell_loc_perc_quot, caption = "Localization of every ORF by Category in percentage", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

#Transform dataset for plotting
cell_loc_plot_quot <- cell_loc_perc_quot %>% pivot_longer(!Category, names_to = "cellular_comp", values_to = "amount")


#Figure SF4d
ImS4d2 <- ggplot(data = cell_loc_plot_quot) +
  geom_bar(aes(x = cellular_comp, y = amount,  fill = Category), position = "fill", stat = "identity") +
theme_light(base_size = 20) +
      theme(legend.text = element_text(size = 18),
            legend.title = element_text(size = 16))+ 
      guides(colour = guide_legend(override.aes = list(size=5))) +
  coord_flip() +
  labs(x = "Cellular Components",
       y = "Percentage of ORFs at each Category")

print(ImS4d2)

ggsave("05_plots/06-Figure_S4d.pdf", 
    height = 8,
    width = 16)


```


## C-terminal domain availability in membrane protein


We want to investigate if the hits are related with the fact that the C-terminal domain is available or not to be recognize by the degradation system. For that, the dataset of hit was compared with a dataset of membrane protein were the C-terminal domain are known to be cytosolic of in the lumen. The dataset was downloaded at 2022-09-13 in the website https://www.pnas.org/doi/10.1073/pnas.0604075103.

```{r C-terminal availability in the membrane proteins}

C_terminal_domain <- read.xlsx(xlsxFile = "06_datasets/20220913_CterminalLocalization.xlsx", sheet = "Table 2 Data")
C_terminal_domain_inLib <- semi_join(C_terminal_domain, df_final, by = "ORF") %>% 
  select(ORF,Gene.name,Cterm)

```


Non Essential genes
```{r C-terminal availability in the membrane proteins Non Essential}


#Attribute each ORF to a cell localization
ORF_Cterm_quot <- inner_join(Non_Ess_Hits_quot[c("ORF")], C_terminal_domain_inLib, by = "ORF", suffix = c(".x",".y"))
ORF_Cterm_quot <- as.data.frame(ORF_Cterm_quot)

#Remove duplicated rows
ORF_Cterm_quot <- ORF_Cterm_quot[!duplicated(ORF_Cterm_quot$ORF),]
rownames(ORF_Cterm_quot) <- ORF_Cterm_quot$ORF

#Filter ORFs with no information

ORF_Cterm_quot <- ORF_Cterm_quot %>% filter(Cterm != "-")

#Quantify how many of each cell localization there is per Category
ORF_Cterm_quot$Cterm[ORF_Cterm_quot$Cterm == "in*"] <- "in"

ORF_Cterm_quot$Cytosol <- ifelse(ORF_Cterm_quot$Cterm == "in", TRUE, FALSE)
ORF_Cterm_quot$Lumen <- ifelse(ORF_Cterm_quot$Cterm != "in", TRUE, FALSE)




cterm_quot <- left_join(ORF_Cterm_quot, Non_Ess_Hits_quot[c("ORF", 'Category')], by="ORF")
cterm_quot <- cterm_quot %>% select(-c(ORF,Gene.name,Cterm)) %>% group_by(Category) %>% summarize_all(sum, na.rm=TRUE) 
colSums(cterm_quot %>% select(-c( Category)), na.rm = TRUE)


#Calculate the percentage of each cell localization per Category
cterm_perc_quot <- adorn_percentages(cterm_quot, denominator = "col", na.rm = TRUE)

#Tables
knitr::kable(cterm_quot, caption = "C-terminal Position of the ORF in the Cellular Membrane by Category", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

knitr::kable(cterm_perc_quot, caption = "C-terminal Position of the ORF in the Cellular Membrane by Category in percentage", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

#Transform dataset for plotting
cterm_plot_quot <- cterm_perc_quot %>% pivot_longer(!Category, names_to = "Membrane_pos", values_to = "amount")

#Figure SF4d
ImS4d3 <- ggplot(data = cterm_plot_quot) +
  geom_bar(aes(x = Membrane_pos, y = amount, fill = Category), position = "fill", stat = "identity") +
  theme_light(base_size = 20) +
      theme(legend.text = element_text(size = 18),
            legend.title = element_text(size = 16))+ 
      guides(colour = guide_legend(override.aes = list(size=5))) +
  coord_flip() +
  labs(x = "C-terminal Position of the ORF",
       y = "Percentage of Membrane ORFs at each Category")

print(ImS4d3)

ggsave("05_plots/07-Figure_S4d.pdf", 
    height = 8,
    width = 16)




```


As before, the same analysis was applied to the Ess dataset

```{r C-terminal availability in the membrane proteins Essential}

#Attribute each ORF to a cell localization
ORF_Cterm_quot <- inner_join(Ess_Hits_quot[c("ORF")], C_terminal_domain_inLib, by = "ORF", suffix = c(".x",".y"))
ORF_Cterm_quot <- as.data.frame(ORF_Cterm_quot)

#Remove duplicated rows
ORF_Cterm_quot <- ORF_Cterm_quot[!duplicated(ORF_Cterm_quot$ORF),]
rownames(ORF_Cterm_quot) <- ORF_Cterm_quot$ORF

#Filter ORFs with no information

ORF_Cterm_quot <- ORF_Cterm_quot %>% filter(Cterm != "-")

#Quantify how many of each cell localization there is per Category
ORF_Cterm_quot$Cterm[ORF_Cterm_quot$Cterm == "in*"] <- "in"

ORF_Cterm_quot$Cytosol <- ifelse(ORF_Cterm_quot$Cterm == "in", TRUE, FALSE)
ORF_Cterm_quot$Lumen <- ifelse(ORF_Cterm_quot$Cterm != "in", TRUE, FALSE)




cterm_quot <- left_join(ORF_Cterm_quot, Ess_Hits_quot[c("ORF", 'Category')], by="ORF")
cterm_quot <- cterm_quot %>% select(-c(ORF,Gene.name,Cterm)) %>% group_by(Category) %>% summarize_all(sum, na.rm=TRUE) 
colSums(cterm_quot %>% select(-c( Category)), na.rm = TRUE)


#Calculate the percentage of each cell localization per Category
cterm_perc_quot <- adorn_percentages(cterm_quot, denominator = "col", na.rm = TRUE)

#Tables
knitr::kable(cterm_quot, caption = "C-terminal Position of the ORF in the Cellular Membrane by Category", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

knitr::kable(cterm_perc_quot, caption = "C-terminal Position of the ORF in the Cellular Membrane by Category in percentage", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

#Transform dataset for plotting
cterm_plot_quot <- cterm_perc_quot %>% pivot_longer(!Category, names_to = "Membrane_pos", values_to = "amount")

#Figure SF4d
ImS4d4 <- ggplot(data = cterm_plot_quot) +
  geom_bar(aes(x = Membrane_pos, y = amount, fill = Category), position = "fill", stat = "identity") +
  theme_light(base_size = 20) +
      theme(legend.text = element_text(size = 18),
            legend.title = element_text(size = 16))+ 
      guides(colour = guide_legend(override.aes = list(size=5))) +
  coord_flip() +
  labs(x = "C-terminal Position of the ORF",
       y = "Percentage of Membrane ORFs at each Category")

print(ImS4d4)

ggsave("05_plots/08-Figure_S4d.pdf", 
    height = 8,
    width = 16)




```


### Dividing data in bins


To check if protein abundance influences the outcome of the induction of protein degradation, the data is going to be separated by bins of equal width and the hits will be plotted accordingly.

```{r}

bins <- read.xlsx(xlsxFile = "06_datasets/Bins.xlsx", sheet = "Sheet 1", sep.names = " ") 
bins <- as.data.frame(bins)


```



```{r Bin Ess}

Hits_Ess_Bins <- rbind((semi_join(Ess_Hits_quot, (bins %>% filter(Bin == 1)), by = "ORF") %>% mutate(Bin = 1)),
                       (semi_join(Ess_Hits_quot, (bins %>% filter(Bin == 2)), by = "ORF") %>% mutate(Bin = 2)),
                       (semi_join(Ess_Hits_quot, (bins %>% filter(Bin == 3)), by = "ORF") %>% mutate(Bin = 3)),
                       (semi_join(Ess_Hits_quot, (bins %>% filter(Bin == 4)), by = "ORF") %>% mutate(Bin = 4)),
                       (semi_join(Ess_Hits_quot, (bins %>% filter(Bin == 5)), by = "ORF") %>% mutate(Bin = 5)))

Hits_Ess_BinsWT <- Hits_Ess_Bins %>% select(c(Category, Bin)) %>% group_by(Category, Bin) %>% count()
Hits_Ess_BinsWT$Category <- factor(Hits_Ess_BinsWT$Category,levels = c("Hit","Not Hit"))

#Figure SF4d
ImS4d5 <- ggplot(data = Hits_Ess_BinsWT) +
  geom_bar(aes(x = Bin, y = n, fill = Category), position = "fill", stat = "identity") +
  theme_light(base_size = 20) +
      theme(legend.text = element_text(size = 18),
            legend.title = element_text(size = 16))+ 
      guides(colour = guide_legend(override.aes = list(size=5))) +
  labs(x = "Bin with equal width of Protein Abundance in log2 scale from mNG data",
       y = "Percentage of ORFs at each bin")

print(ImS4d5)

ggsave("05_plots/09-Figure_S4d.pdf", 
    height = 8,
    width = 16)



```

```{r Bins Non Essential Genes}

Hits_Bins <- rbind((semi_join(Non_Ess_Hits_quot, (bins %>% filter(Bin == 1)), by = "ORF") %>% mutate(Bin = 1)),
                       (semi_join(Non_Ess_Hits_quot, (bins %>% filter(Bin == 2)), by = "ORF") %>% mutate(Bin = 2)),
                       (semi_join(Non_Ess_Hits_quot, (bins %>% filter(Bin == 3)), by = "ORF") %>% mutate(Bin = 3)),
                       (semi_join(Non_Ess_Hits_quot, (bins %>% filter(Bin == 4)), by = "ORF") %>% mutate(Bin = 4)),
                       (semi_join(Non_Ess_Hits_quot, (bins %>% filter(Bin == 5)), by = "ORF") %>% mutate(Bin = 5)))

Hits_BinsWT <- Hits_Bins %>% select(c(Category, Bin)) %>% group_by(Category, Bin) %>% count()
Hits_BinsWT$Category <- factor(Hits_BinsWT$Category,levels = c("Hit","Not Hit"))


#Figure SF4d
ImS4d6 <- ggplot(data = Hits_BinsWT) +
  geom_bar(aes(x = Bin, y = n, fill = Category), position = "fill", stat = "identity") +
  theme_light(base_size = 20) +
      theme(legend.text = element_text(size = 18),
            legend.title = element_text(size = 16))+ 
      guides(colour = guide_legend(override.aes = list(size=5))) +
  labs(x = "Bin with equal width of Protein Abundance in log2 scale from mNG data",
       y = "Percentage of ORFs at each bin")

print(ImS4d6)

ggsave("05_plots/10-Figure_S4d.pdf", 
    height = 8,
    width = 16)



```


## Stratification of the data in Essential and Non-Essential Hits

Since it was defined by the library v1 which proteins can be completely degraded or not, the hits were stratified with the categories.
```{r}

mNG_Colonies <- read.xlsx(xlsxFile = "06_datasets/Library_v1_final_table.xlsx", sheet = "Categorization_Fluorescence") %>%
  select(plate, ORF, gene, mNG_final_ctrl, mNG_ORFnorm_deg, Category)

```



```{r Stratification of the data - Essential}



#Attribute each ORF to a category
ORF_Ess_Cat_quot <- inner_join(Ess_Hits_quot[c("ORF")], mNG_Colonies, by = "ORF", suffix = c(".x",".y"))
ORF_Ess_Cat_quot <- as.data.frame(ORF_Ess_Cat_quot)

#Remove duplicated rows
ORF_Ess_Cat_quot <- ORF_Ess_Cat_quot[!duplicated(ORF_Ess_Cat_quot$ORF),]
rownames(ORF_Ess_Cat_quot) <- ORF_Ess_Cat_quot$ORF


#Quantify how many of each cell localization there is per Category

ORF_Ess_Cat_quot$Complete <- ifelse(ORF_Ess_Cat_quot$Category == "Complete degradation", TRUE, FALSE)
ORF_Ess_Cat_quot$Partial <- ifelse(ORF_Ess_Cat_quot$Category == "Partial degradation", TRUE, FALSE)
ORF_Ess_Cat_quot$No <- ifelse(ORF_Ess_Cat_quot$Category == "No degradation", TRUE, FALSE)
ORF_Ess_Cat_quot$NotD <- ifelse(ORF_Ess_Cat_quot$Category == "Not detectable", TRUE, FALSE)




ess_cat_quot <- left_join(ORF_Ess_Cat_quot, Ess_Hits_quot[c("ORF", 'Category')], by="ORF")
ess_cat_quot <- ess_cat_quot %>% select(-c(ORF,plate,gene,mNG_final_ctrl, mNG_ORFnorm_deg,Category.x)) %>% group_by(Category.y) %>% summarize_all(sum, na.rm=TRUE) 
colSums(ess_cat_quot %>% select(-c( Category.y)), na.rm = TRUE)


#Calculate the percentage of each cell localization per Category
ess_cat_perc_quot <- adorn_percentages(ess_cat_quot, denominator = "col", na.rm = TRUE)

#Tables
knitr::kable(ess_cat_quot, caption = "C-terminal Position of the ORF in the Cellular Membrane by Category", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

knitr::kable(ess_cat_perc_quot, caption = "C-terminal Position of the ORF in the Cellular Membrane by Category in percentage", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

#Transform dataset for plotting
ess_cat_plot_quot <- ess_cat_perc_quot %>% pivot_longer(!Category.y, names_to = "Category", values_to = "amount")





#Figure SF4c
ImS4c <- ggplot(data = ess_cat_plot_quot) +
  geom_bar(aes(x = Category, y = amount, fill = Category.y), position = "fill", stat = "identity") +
  theme_light(base_size = 20) +
      theme(legend.text = element_text(size = 18),
            legend.title = element_text(size = 16))+ 
      guides(colour = guide_legend(override.aes = list(size=5))) +
  coord_flip() +
  labs(x = "Category",
       y = "Percentage of Hits at each Category")

print(ImS4c)

ggsave("05_plots/11-Figure_S4c.pdf", 
    height = 8,
    width = 16)



```

```{r Stratification of the data - Non Essential}



#Attribute each ORF to a category
ORF_Non_Ess_Cat_quot <- inner_join(Non_Ess_Hits_quot[c("ORF")], mNG_Colonies, by = "ORF", suffix = c(".x",".y"))
ORF_Non_Ess_Cat_quot <- as.data.frame(ORF_Non_Ess_Cat_quot)

#Remove duplicated rows
ORF_Non_Ess_Cat_quot <- ORF_Non_Ess_Cat_quot[!duplicated(ORF_Non_Ess_Cat_quot$ORF),]
rownames(ORF_Non_Ess_Cat_quot) <- ORF_Non_Ess_Cat_quot$ORF


#Quantify how many of each cell localization there is per Category

ORF_Non_Ess_Cat_quot$Complete <- ifelse(ORF_Non_Ess_Cat_quot$Category == "Complete degradation", TRUE, FALSE)
ORF_Non_Ess_Cat_quot$Partial <- ifelse(ORF_Non_Ess_Cat_quot$Category == "Partial degradation", TRUE, FALSE)
ORF_Non_Ess_Cat_quot$No <- ifelse(ORF_Non_Ess_Cat_quot$Category == "No degradation", TRUE, FALSE)
ORF_Non_Ess_Cat_quot$NotD <- ifelse(ORF_Non_Ess_Cat_quot$Category == "Not detectable", TRUE, FALSE)




non_ess_cat_quot <- left_join(ORF_Non_Ess_Cat_quot, Non_Ess_Hits_quot[c("ORF", 'Category')], by="ORF")
non_ess_cat_quot <- non_ess_cat_quot %>% select(-c(ORF,plate,gene,mNG_final_ctrl, mNG_ORFnorm_deg,Category.x)) %>% group_by(Category.y) %>% summarize_all(sum, na.rm=TRUE) 
colSums(non_ess_cat_quot %>% select(-c( Category.y)), na.rm = TRUE)


#Calculate the percentage of each cell localization per Category
non_ess_cat_perc_quot <- adorn_percentages(non_ess_cat_quot, denominator = "col", na.rm = TRUE)

#Tables
knitr::kable(non_ess_cat_quot, caption = "C-terminal Position of the ORF in the Cellular Membrane by Category", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

knitr::kable(non_ess_cat_quot, caption = "C-terminal Position of the ORF in the Cellular Membrane by Category in percentage", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

#Transform dataset for plotting
non_ess_cat_plot_quot <- non_ess_cat_perc_quot %>% pivot_longer(!Category.y, names_to = "Category", values_to = "amount")

##Figure SF4c
ImS4c2 <- ggplot(data = non_ess_cat_plot_quot) +
  geom_bar(aes(x = Category, y = amount, fill = Category.y), position = "fill", stat = "identity") +
  theme_light(base_size = 20) +
      theme(legend.text = element_text(size = 18),
            legend.title = element_text(size = 16))+ 
      guides(colour = guide_legend(override.aes = list(size=5))) +
  coord_flip() +
  labs(x = "Category",
       y = "Percentage of Hits at each Category")

print(ImS4c2)

ggsave("05_plots/12-Figure_S4c.pdf", 
    height = 8,
    width = 16)




```

# Drug treatments

We wanted to test if the degron library could also be used for screening with drugs. That is, if the degron library behaves as a deletion when expose to a known sensitive drug. For that, three different drugs were used: CPT, HU and MMS.

## Data Visualization

The data, as it was previously done for the Essential genes screen, what plotted in Scatter plots. The majority of the hits are essential hits that were already discussed.

## Comparison with known databases

To compare the obtained results with known databases for Drug sensitivity, it is first important to create a list of real hits from this screen. For that, all the hits obtained in the Pre-pin, Control YPD plate and IAA plate will be removed from the pool of hit genes with HU and CPT. Another list will also be created where the hits that are shared between the drug plates with or without auxin are removed. This is because the tag on the protein could already influence in some way the protein function, which could indicate that that specific strain is also sensitive to the DNA Damage agent but the tag turn the protein in an hypomorphic protein.

### MMS
```{r MMS Database}
Drug_Genes <- read.xlsx(xlsxFile = "06_datasets/20221115_MMS_Boone.xlsx", sheet = "Sheet1") %>%
  `colnames<-`(c("ORF", colnames(.)[2:4]))
MMS_Genes_inLib <- semi_join(Drug_Genes, df_spread_final_1, by = "ORF")


```


### HU and CPT
```{r Hu and CPT Database}
Drug_Int_Genes <- read.xlsx(xlsxFile = "06_datasets/20221103_Drugs_Integration.xlsx", sheet = "Sheet1") %>%
  `colnames<-`(c("ORF", colnames(.)[2:14]))
Drug_Int_Genes_inLib <- semi_join(Drug_Int_Genes, df_final, by = "ORF")

#CPT and HU genes in the Library
CPT_Int_Genes_inLib <- Drug_Int_Genes_inLib %>% filter(Camptothecin == "1" | Camptothecin == "2" | Camptothecin == "3")

HU_Int_Genes_inLib <- Drug_Int_Genes_inLib %>% filter(Hydroxyurea == "1" | Hydroxyurea == "2" | Hydroxyurea == "3")

```

### Deletion Collection

```{r Deletion Collection}

Deletion_Collection <- read.xlsx(xlsxFile = "06_datasets/20221115_Deletion_collection.xlsx", sheet = "Sheet1")
Delection_Collection_inLib <- semi_join(Deletion_Collection, df_final, by = "ORF")

```


## Chemo-Genetic interaction scores

We now want to calculate a chemo-genetic interaction score. The principle is that, if the two single conditions are independent, when together, the growth defect should be the multiplication of the single condition (https://doi.org/10.1016/j.coisb.2017.08.002). So, the chemo-genetic interaction score will be calculated for the 3 drugs, to see if the obtained hits with the Quotient are similar. These calculations can only be performed with the normalized size so thre is no different between quotient and Z-score hits.

### MMS

```{r Chemo-Genetic interations scores}

#MMS

CG_MMS_d2 <- df_norm_3 %>%
  # Separate in two tables
  do ({
    tmp <- subset(., ori_plate_type == "IAA_d1") %>% select(-ori_plate_type)
    tmp2 <- subset(., ori_plate_type == "MMS_d2") %>% select(-ori_plate_type)
    tmp3 <- full_join(tmp, tmp2, by = c("plate", "ORF", "gene", "well"),
              suffix = c("_IAA", "_MMS"))
    tmp4 <- subset(., ori_plate_type == "MMS_IAA_d2") %>% select(-ori_plate_type)
    full_join(tmp3, tmp4, by = c("plate", "ORF", "gene", "well"))
  }) %>%
  #Calculate Chemo-genetic interactions
  mutate(CG = pnorm3_IAA*pnorm3_MMS) %>%
  select(plate, ORF, gene, pnorm3_IAA,pnorm3_MMS,pnorm3, CG)


CG_MMS_p_d2 <- CG_MMS_d2 %>%
   #Filter
  group_by(plate, ORF, gene) %>%
  filter(n() > 1) %>%
  #Calculate Medians and p-value
  summarise(size_median_IAA = median(pnorm3_IAA, na.rm = T),
            size_median_MMS = median(pnorm3_MMS, na.rm = T),
            size_median_MMS_IAA = median(pnorm3, na.rm = T),
            size_median_CG = median(CG, na.rm = T),
            pvaluesize = tryCatch({t.test(x = pnorm3, y = CG, paired = FALSE)$p.value}, error = function(e){NA}),
            df_size = tryCatch({t.test(x = pnorm3, y = CG, paired = FALSE)$parameter}, error = function(e){NA})) %>%
  #Adjust p-value
  mutate(BHsize = p.adjust(pvaluesize, method = "BH")) %>%
  #Calculate quotients
  mutate(delta_size_CG = size_median_MMS_IAA-size_median_CG) 
CG_MMS_p_d2 <- CG_MMS_p_d2[!duplicated(CG_MMS_p_d2$ORF),]
CG_MMS_p_d2 <- CG_MMS_p_d2 %>% drop_na(ORF)
 
#Hits  
Hits_CG_MMS_d2 <- CG_MMS_d2 %>%
   #Filter
  group_by(plate, ORF, gene) %>%
  filter(n() > 1) %>%
  #Calculate Medians and p-value
  summarise(size_median_IAA = median(pnorm3_IAA, na.rm = T),
            size_median_MMS = median(pnorm3_MMS, na.rm = T),
            size_median_MMS_IAA = median(pnorm3, na.rm = T),
            size_median_CG = median(CG, na.rm = T),
            pvaluesize = tryCatch({t.test(x = pnorm3, y = CG, paired = FALSE)$p.value}, error = function(e){NA}),
            df_size = tryCatch({t.test(x = pnorm3, y = CG, paired = FALSE)$parameter}, error = function(e){NA})) %>%
  #Adjust p-value
  mutate(BHsize = p.adjust(pvaluesize, method = "BH")) %>%
  #Calculate quotients
  mutate(delta_size_CG = size_median_MMS_IAA-size_median_CG) %>%
   filter(delta_size_CG <= -0.20,
          size_median_MMS_IAA <= 0.9,
          BHsize < BHThres) %>%
  drop_na(ORF) %>%
  select(plate, ORF, gene,size_median_IAA,size_median_MMS,size_median_MMS_IAA, size_median_CG, delta_size_CG, df_size, BHsize)
Hits_CG_MMS_d2 <- Hits_CG_MMS_d2[!duplicated(Hits_CG_MMS_d2$ORF),]

#Hits that are part of the deletion collection
Hits_CG_MMS_Del_d2 <- semi_join(Hits_CG_MMS_d2,Delection_Collection_inLib, by = "ORF")

#Figure S5b
pdf("05_plots/13-Figure_S5b.pdf", 
    height = 8,
    width = 16)

grid.newpage()
grid.draw(venn.diagram(x = list("Database" = MMS_Genes_inLib$ORF,
                                "MMS" = Hits_CG_MMS_Del_d2$ORF),
  filename = NULL, disable.logging = T,
  main = "Overlap of hits from Database and Hits on MMS",
  main.cex = 1.5,
  sub = "Only genes from the deletion collection and are specific hits in the MMS plates",
  sub.cex = 1.1,
  sub.col = "black",
  col = "transparent",
	fill = c("green4", "orangered2"),
	cex = 2,
	alpha = 0.3,
	label.col = "black",
	lty = 1,
	fontface = "bold",
	cat.col = c("darkgreen", "darkred"),
	cat.cex = 2,
	cat.dist = 0.1,
	margin = 0.1))


dev.off()

#Scatter plot of Hits obtained by Chemical-Genetic interactions
ScatterMMS <- rbind((anti_join(df_spread_final_1, Hits_CG_MMS_d2 , by = "ORF") %>% mutate(Fitness = "No defect")), (semi_join(df_spread_final_1, Hits_CG_MMS_d2 , by = "ORF") %>% mutate(Fitness = "Fitness defect")))



grid.arrange(
    ggplot(ScatterMMS) +
      geom_point(aes(ctrl_d1, IAA_d1, color = Fitness), alpha = 0.3),
    ggplot(ScatterMMS) +
      geom_point(aes(ctrl_d1, MMS_d2, color = Fitness), alpha = 0.3),
    ggplot(ScatterMMS) +
      geom_point(aes(ctrl_d1, MMS_IAA_d2, color = Fitness), alpha = 0.3),
    ggplot(ScatterMMS) +
      geom_point(aes(IAA_d1, MMS_IAA_d2, color = Fitness), alpha = 0.3),
    ggplot(ScatterMMS) +
      geom_point(aes(MMS_d2, IAA_d1, color = Fitness), alpha = 0.3),
    ggplot(ScatterMMS) +
      geom_point(aes(MMS_d2, MMS_IAA_d2, color = Fitness), alpha = 0.3) ,
    ncol = 2,
    nrow = 3)




```


#### Volcano Blot

```{r}

#Defining Rad52 Epistatic group

Rad52_E_MMS <- CG_MMS_p_d2 %>% filter(ORF == "YNL250W" |
                                      ORF == "YER095W" |
                                      ORF == "YML032C" |
                                      ORF == "YGL163C" |
                                      ORF == "YBR073W" |
                                      ORF == "YDR076W" |
                                      ORF == "YDR004W" |
                                      ORF == "YDL059C" |
                                      ORF == "YMR224C" |
                                      ORF == "YDR369C")


#Figure 4b
Im4b <- ggplot() + 
  geom_point(data = CG_MMS_p_d2,
             aes(delta_size_CG, -log10(BHsize)),
             alpha = 0.2) +
  geom_point(data = Hits_CG_MMS_d2,
             aes(delta_size_CG, -log10(BHsize)),
             alpha = 0.2, col = "red") +
  geom_point(data = Rad52_E_MMS,
             aes(delta_size_CG, -log10(BHsize)),
             alpha = 0.2, col = "blue") +
  labs(x = "CG", y = "-Log10(BH-adjusted p-value)",
       title = "Volcano plot with significant hits highlighted (MMS).",
       subtitle = paste("Thresholds applied:",
                        "\nBH-adjusted p-value < ", BHThres,
                        "\nCG <", -0.2,
                        "\nFitness 5-Ph-IAA + DDA <=", 0.9))

print(Im4b)

ggsave("05_plots/14-Figure_4b.pdf", 
    height = 8,
    width = 16)

```



### HU

```{r Chemo-Genetic interations scores HU}

#HU

CG_HU_d2 <- df_norm_3 %>%
  # Separate in two tables
  do ({
    tmp <- subset(., ori_plate_type == "IAA_d1") %>% select(-ori_plate_type)
    tmp2 <- subset(., ori_plate_type == "HU_d2") %>% select(-ori_plate_type)
    tmp3 <- full_join(tmp, tmp2, by = c("plate", "ORF", "gene", "well"),
              suffix = c("_IAA", "_HU"))
    tmp4 <- subset(., ori_plate_type == "HU_IAA_d2") %>% select(-ori_plate_type)
    full_join(tmp3, tmp4, by = c("plate", "ORF", "gene", "well"))
  }) %>%
  #Calculate Chemo-genetic interactions
  mutate(CG = pnorm3_IAA*pnorm3_HU) %>%
  select(plate, ORF, gene, pnorm3_IAA,pnorm3_HU,pnorm3, CG)


CG_HU_p_d2 <- CG_HU_d2 %>%
   #Filter
  group_by(plate, ORF, gene) %>%
  filter(n() > 1) %>%
  #Calculate Medians and p-value
  summarise(size_median_IAA = median(pnorm3_IAA, na.rm = T),
            size_median_HU = median(pnorm3_HU, na.rm = T),
            size_median_HU_IAA = median(pnorm3, na.rm = T),
            size_median_CG = median(CG, na.rm = T),
            pvaluesize = tryCatch({t.test(x = pnorm3, y = CG, paired = FALSE)$p.value}, error = function(e){NA}),
            df_size = tryCatch({t.test(x = pnorm3, y = CG, paired = FALSE)$parameter}, error = function(e){NA})) %>%
  #Adjust p-value
  mutate(BHsize = p.adjust(pvaluesize, method = "BH")) %>%
  #Calculate quotients
  mutate(delta_size_CG = size_median_HU_IAA-size_median_CG)
CG_HU_p_d2  <- CG_HU_p_d2 [!duplicated(CG_HU_p_d2 $ORF),]
CG_HU_p_d2 <- CG_HU_p_d2 %>% drop_na(ORF)
 
 
#Hits  
Hits_CG_HU_d2 <- CG_HU_d2 %>%
   #Filter
  group_by(plate, ORF, gene) %>%
  filter(n() > 1) %>%
  #Calculate Medians and p-value
  summarise(size_median_IAA = median(pnorm3_IAA, na.rm = T),
            size_median_HU = median(pnorm3_HU, na.rm = T),
            size_median_HU_IAA = median(pnorm3, na.rm = T),
            size_median_CG = median(CG, na.rm = T),
            pvaluesize = tryCatch({t.test(x = pnorm3, y = CG, paired = FALSE)$p.value}, error = function(e){NA}),
            df_size = tryCatch({t.test(x = pnorm3, y = CG, paired = FALSE)$parameter}, error = function(e){NA})) %>%
  #Adjust p-value
  mutate(BHsize = p.adjust(pvaluesize, method = "BH")) %>%
  #Calculate quotients
  mutate(delta_size_CG = size_median_HU_IAA-size_median_CG) %>%
   filter(delta_size_CG <= -0.20,
          size_median_HU_IAA <= 0.9,
          BHsize < BHThres) %>%
  drop_na(ORF) %>%
  select(plate, ORF, gene,size_median_IAA,size_median_HU,size_median_HU_IAA, size_median_CG, delta_size_CG, df_size, BHsize)
Hits_CG_HU_d2 <- Hits_CG_HU_d2[!duplicated(Hits_CG_HU_d2$ORF),]


#Hits that are part of the deletion collection
Hits_CG_HU_Del_d2 <- semi_join(Hits_CG_HU_d2,Delection_Collection_inLib, by = "ORF")

#Figure S5b

pdf("05_plots/15-Figure_S5b.pdf", 
    height = 8,
    width = 16)
grid.newpage()
grid.draw(venn.diagram(x = list("Database" = HU_Int_Genes_inLib$ORF,
                                "HU" = Hits_CG_HU_Del_d2$ORF),
  filename = NULL, disable.logging = T,
  main = "Overlap of hits from Database and Hits on HU",
  main.cex = 1.5,
  sub = "Only genes from the deletion collection and are specific hits in the HU plates",
  sub.cex = 1.1,
  sub.col = "black",
  col = "transparent",
	fill = c("green4", "orangered2"),
	cex = 2,
	alpha = 0.3,
	label.col = "black",
	lty = 1,
	fontface = "bold",
	cat.col = c("darkgreen", "darkred"),
	cat.cex = 2,
	cat.dist = 0.1,
	margin = 0.1))

dev.off()





```

Volcano Blot

```{r}

#Defining Rad52 Epistatic group
Rad52_E_HU <- CG_HU_p_d2 %>% filter(ORF == "YNL250W" |
                                      ORF == "YER095W" |
                                      ORF == "YML032C" |
                                      ORF == "YGL163C" |
                                      ORF == "YBR073W" |
                                      ORF == "YDR076W" |
                                      ORF == "YDR004W" |
                                      ORF == "YDL059C" |
                                      ORF == "YMR224C" |
                                      ORF == "YDR369C")

#Figure 4b

Im4b2 <- ggplot() + 
  geom_point(data = CG_HU_p_d2,
             aes(delta_size_CG, -log10(BHsize)),
             alpha = 0.2) +
  geom_point(data = Hits_CG_HU_d2,
             aes(delta_size_CG, -log10(BHsize)),
             alpha = 0.2, col = "red") +
  geom_point(data = Rad52_E_HU,
             aes(delta_size_CG, -log10(BHsize)),
             alpha = 0.2, col = "blue") +
  labs(x = "CG", y = "-Log10(BH-adjusted p-value)",
       title = "Volcano plot with significant hits highlighted (HU).",
       subtitle = paste("Thresholds applied:",
                        "\nBH-adjusted p-value < ", BHThres,
                        "\nCG <", -0.2,
                        "\nFitness 5-Ph-IAA + DDA <=", 0.9))

print(Im4b2)

ggsave("05_plots/16-Figure_4b.pdf", 
    height = 8,
    width = 16)


```

Now we want to know how many essential genes per condition we have that are not in the Venn diagrams

```{r}

#Hits that are not part of the Deletion Collection
Hits_CG_HU_NonDel_d2 <- anti_join(Hits_CG_HU_d2,Delection_Collection_inLib, by = "ORF")

#Hits are Essential or Not essential
Hits_CG_HU_NonDel_d2 <- rbind((semi_join(Hits_CG_HU_NonDel_d2,Ess_Genes_inLib, by = "ORF") %>% mutate(Ess = "Yes")),(anti_join(Hits_CG_HU_NonDel_d2,Ess_Genes_inLib, by = "ORF") %>% mutate(Ess = "No")))

#Defining all hits according if they are present in which screen dataset




```




### CPT

```{r Chemo-Genetic interations scores CPT}

#CPT

CG_CPT_d1 <- df_norm_3 %>%
  # Separate in two tables
  do ({
    tmp <- subset(., ori_plate_type == "IAA_d1") %>% select(-ori_plate_type)
    tmp2 <- subset(., ori_plate_type == "CPT_d1") %>% select(-ori_plate_type)
    tmp3 <- full_join(tmp, tmp2, by = c("plate", "ORF", "gene", "well"),
              suffix = c("_IAA", "_CPT"))
    tmp4 <- subset(., ori_plate_type == "CPT_IAA_d1") %>% select(-ori_plate_type)
    full_join(tmp3, tmp4, by = c("plate", "ORF", "gene", "well"))
  }) %>%
  #Calculate Chemo-genetic interactions
  mutate(CG = pnorm3_IAA*pnorm3_CPT) %>%
  select(plate, ORF, gene, pnorm3_IAA,pnorm3_CPT,pnorm3, CG)

CG_CPT_p_d1 <- CG_CPT_d1 %>%
   #Filter
  group_by(plate, ORF, gene) %>%
  filter(n() > 1) %>%
  #Calculate Medians and p-value
  summarise(size_median_IAA = median(pnorm3_IAA, na.rm = T),
            size_median_CPT = median(pnorm3_CPT, na.rm = T),
            size_median_CPT_IAA = median(pnorm3, na.rm = T),
            size_median_CG = median(CG, na.rm = T),
            pvaluesize = tryCatch({t.test(x = pnorm3, y = CG, paired = FALSE)$p.value}, error = function(e){NA}),
            df_size = tryCatch({t.test(x = pnorm3, y = CG, paired = FALSE)$parameter}, error = function(e){NA})) %>%
  #Adjust p-value
  mutate(BHsize = p.adjust(pvaluesize, method = "BH")) %>%
  #Calculate quotients
  mutate(delta_size_CG = size_median_CPT_IAA-size_median_CG)
CG_CPT_p_d1 <- CG_CPT_p_d1[!duplicated(CG_CPT_p_d1$ORF),]
CG_CPT_p_d1 <- CG_CPT_p_d1 %>% drop_na(ORF)
 
#Hits  
Hits_CG_CPT_d1 <- CG_CPT_d1 %>%
   #Filter
  group_by(plate, ORF, gene) %>%
  filter(n() > 1) %>%
  #Calculate Medians and p-value
  summarise(size_median_IAA = median(pnorm3_IAA, na.rm = T),
            size_median_CPT = median(pnorm3_CPT, na.rm = T),
            size_median_CPT_IAA = median(pnorm3, na.rm = T),
            size_median_CG = median(CG, na.rm = T),
            pvaluesize = tryCatch({t.test(x = pnorm3, y = CG, paired = FALSE)$p.value}, error = function(e){NA}),
            df_size = tryCatch({t.test(x = pnorm3, y = CG, paired = FALSE)$parameter}, error = function(e){NA})) %>%
  #Adjust p-value
  mutate(BHsize = p.adjust(pvaluesize, method = "BH")) %>%
  #Calculate quotients
  mutate(delta_size_CG = size_median_CPT_IAA-size_median_CG) %>%
   filter(delta_size_CG <= -0.20,
          size_median_CPT_IAA <= 0.9,
          BHsize < BHThres) %>%
  drop_na(ORF) %>%
  select(plate, ORF, gene,size_median_IAA,size_median_CPT,size_median_CPT_IAA, size_median_CG, delta_size_CG, df_size, BHsize)
Hits_CG_CPT_d1 <- Hits_CG_CPT_d1[!duplicated(Hits_CG_CPT_d1$ORF),]


#Hits that are part of the deletion collection
Hits_CG_CPT_Del_d1 <- semi_join(Hits_CG_CPT_d1,Delection_Collection_inLib, by = "ORF")



#Figure S5b

pdf("05_plots/17-Figure_S5b.pdf", 
    height = 8,
    width = 16)
grid.newpage()
grid.draw(venn.diagram(x = list("Database" = CPT_Int_Genes_inLib$ORF,
                                "CPT" = Hits_CG_CPT_Del_d1$ORF),
  filename = NULL, disable.logging = T,
  main = "Overlap of hits from Database and Hits on HU",
  main.cex = 1.5,
  sub = "Only genes from the deletion collection and are specific hits in the CPT plates",
  sub.cex = 1.1,
  sub.col = "black",
  col = "transparent",
	fill = c("green4", "orangered2"),
	cex = 2,
	alpha = 0.3,
	label.col = "black",
	lty = 1,
	fontface = "bold",
	cat.col = c("darkgreen", "darkred"),
	cat.cex = 2,
	cat.dist = 0.1,
	margin = 0.1))

dev.off()






```


Volcano Blot

```{r}

#Defining Rad52 Epistatic group
Rad52_E_CPT <- CG_CPT_p_d1 %>% filter(ORF == "YNL250W" |
                                      ORF == "YER095W" |
                                      ORF == "YML032C" |
                                      ORF == "YGL163C" |
                                      ORF == "YBR073W" |
                                      ORF == "YDR076W" |
                                      ORF == "YDR004W" |
                                      ORF == "YDL059C" |
                                      ORF == "YMR224C" |
                                      ORF == "YDR369C")


#Figure 4b
Im4b3 <- ggplot() + 
  geom_point(data = CG_CPT_p_d1,
             aes(delta_size_CG, -log10(BHsize)),
             alpha = 0.2) +
  geom_point(data = Hits_CG_CPT_d1,
             aes(delta_size_CG, -log10(BHsize)),
             alpha = 0.2, col = "red") +
  geom_point(data = Rad52_E_CPT,
             aes(delta_size_CG, -log10(BHsize)),
             alpha = 0.2, col = "blue") +
  labs(x = "CG", y = "-Log10(BH-adjusted p-value)",
       title = "Volcano plot with significant hits highlighted (CPT).",
       subtitle = paste("Thresholds applied:",
                        "\nBH-adjusted p-value < ", BHThres,
                        "\nCG <", -0.2,
                        "\nFitness 5-Ph-IAA + DDA <=", 0.9))

print(Im4b3)

ggsave("05_plots/18-Figure_4b.pdf", 
    height = 8,
    width = 16)


```


### Comparison of the data between all the conditions

```{r}

#Figure 4c

pdf("05_plots/19-Figure_4c.pdf", 
    height = 8,
    width = 16)
grid.newpage()
grid.draw(venn.diagram(x = list("CPT" = Hits_CG_CPT_d1$ORF,
                                "HU" = Hits_CG_HU_d2$ORF,
                                "MMS" = Hits_CG_MMS_d2$ORF),
  filename = NULL, disable.logging = T,
  main = "Overlap of hits from all screens",
  main.cex = 1.5,
  sub = "Hits obtained by CG",
  sub.cex = 1.1,
  sub.col = "black",
  col = "transparent",
	fill = c("green4", "orangered2", "blue"),
	cex = 2,
	alpha = 0.3,
	label.col = "black",
	lty = 1,
	fontface = "bold",
	cat.col = c("darkgreen", "darkred", "darkblue"),
	cat.cex = 2,
	cat.dist = 0.1,
	margin = 0.1))

dev.off()


```

### Union between Drug hits

```{r}

MMS_HU <- union((Hits_CG_MMS_d2 %>% select(ORF, gene)), (Hits_CG_HU_d2 %>% select(ORF, gene)))
Drug_Hits <- union((Hits_CG_CPT_d1 %>% select(ORF, gene)), MMS_HU)

Drug_Hits_1 <- inner_join(Drug_Hits, CG_CPT_p_d1, by = c("ORF","gene")) %>% mutate(CPT = delta_size_CG) %>% select(ORF, gene, CPT)
Drug_Hits_2 <- inner_join(Drug_Hits_1, CG_MMS_p_d2, by = c("ORF","gene")) %>% mutate(MMS = delta_size_CG) %>% select(ORF, gene, CPT, MMS)
Drug_Hits_3 <- inner_join(Drug_Hits_2, CG_HU_p_d2, by = c("ORF","gene")) %>% mutate(HU = delta_size_CG) %>% select(ORF, gene, CPT, MMS, HU)


Drug_Hits_CG_L <- pivot_longer(Drug_Hits_3, c("CPT", "MMS", "HU"))
Drug_Hits_CG <- rbind((semi_join(Drug_Hits_CG_L, Ess_Genes_inLib, by = "ORF") %>% mutate(Essential = T )),(anti_join(Drug_Hits_CG_L, Ess_Genes_inLib, by = "ORF") %>% mutate(Essential = F )))

Drug_Hits_CG <- rbind((semi_join(Drug_Hits_CG, MMS_Genes_inLib, by = "ORF") %>% mutate(Screen_MMS = T )),(anti_join(Drug_Hits_CG, MMS_Genes_inLib, by = "ORF") %>% mutate(Screen_MMS = F ))) 
Drug_Hits_CG <- rbind((semi_join(Drug_Hits_CG, HU_Int_Genes_inLib, by = "ORF") %>% mutate(Screen_HU = T )),(anti_join(Drug_Hits_CG, HU_Int_Genes_inLib, by = "ORF") %>% mutate(Screen_HU = F )))
Drug_Hits_CG <- rbind((semi_join(Drug_Hits_CG, CPT_Int_Genes_inLib, by = "ORF") %>% mutate(Screen_CPT = T )),(anti_join(Drug_Hits_CG, CPT_Int_Genes_inLib, by = "ORF") %>% mutate(Screen_CPT = F )))

```

Now we want to try to incorporate the GOSlim terms from SGD.

```{r}
#GoTerms from GoSLIM from SGD
GoTerms <- read.xlsx(xlsxFile = "06_datasets/GoTerms.xlsx", sheet = "Sheet1")

GoTerms_Drugs <- GoTerms %>% pivot_longer(!TERM, names_to = "x", values_to = "ORF") %>% drop_na() %>% select(-x)

GoTerms_Drugs$value <- TRUE

#Table with GoTerms
GoTerms_Drugs <- GoTerms_Drugs %>% pivot_wider(names_from = TERM,
                            values_from = value,
                            values_fill = FALSE) 

#Merge size values with GoTerms
GoTerms_Drugs <- left_join(Drug_Hits_3, GoTerms_Drugs, by = "ORF")

#Remove double entries to have only the positive ones
tmp <- GoTerms_Drugs
GoTerms_Drugs <- GoTerms_Drugs %>% replace(is.na(tmp), FALSE)


```


```{r}

#Extent the data for easiness
GoTerms_Drugs <- GoTerms_Drugs %>% select(-CPT, -HU, -MMS) %>% pivot_longer(3:50, names_to = "Goterm", values_to = "Exist")
GoTerms_Drugs$Exist <- as.numeric(GoTerms_Drugs$Exist)

GoTerms_Drugs <- GoTerms_Drugs %>%
  mutate(name = Goterm,
         value = Exist) %>% 
  select(-Goterm,-Exist)

#Add value for each Goterm
GoTerms_Drugs <- bind_rows(Drug_Hits_CG_L,GoTerms_Drugs)


```

We now want to couple some of the GoTerms together so it is easier to read.

```{r}

#Merge GoSlim Terms together
GoTerms_R <- GoTerms_Drugs %>% 
  mutate(name = replace(name, name == "DNA repair", "DNA repair, DNA recombination, and DNA damage response")) %>%
  mutate(name = replace(name, name == "DNA recombination", "DNA repair, DNA recombination, and DNA damage response")) %>%
  mutate(name = replace(name, name == "DNA damage response", "DNA repair, DNA recombination, and DNA damage response")) %>%
  
  mutate(name = replace(name, name == "meiotic cell cycle", "Meiotic cell cycle, mitotic cell cycle, regulation of cell cycle, DNA replication, sporulation, and chromosome segregation")) %>%
  mutate(name = replace(name, name == "mitotic cell cycle", "Meiotic cell cycle, mitotic cell cycle, regulation of cell cycle, DNA replication, sporulation, and chromosome segregation")) %>%
  mutate(name = replace(name, name == "regulation of cell cycle", "Meiotic cell cycle, mitotic cell cycle, regulation of cell cycle, DNA replication, sporulation, and chromosome segregation")) %>%
  mutate(name = replace(name, name == "DNA replication", "Meiotic cell cycle, mitotic cell cycle, regulation of cell cycle, DNA replication, sporulation, and chromosome segregation")) %>%
  mutate(name = replace(name, name == "sporulation", "Meiotic cell cycle, mitotic cell cycle, regulation of cell cycle, DNA replication, sporulation, and chromosome segregation")) %>%
  mutate(name = replace(name, name == "chromosome segregation", "Meiotic cell cycle, mitotic cell cycle, regulation of cell cycle, DNA replication, sporulation, and chromosome segregation")) %>%
  
  mutate(name = replace(name, name == "endosomal transport", "Endosomal transport, Transmembrane transport, vacuole organization, endocytosis, Golgi vesicle transport, membrane fusion, vesicle organization, lipid metabolic process, and protein targeting")) %>%
  mutate(name = replace(name, name == "transmembrane transport", "Endosomal transport, Transmembrane transport, vacuole organization, endocytosis, Golgi vesicle transport, membrane fusion, vesicle organization, lipid metabolic process, and protein targeting")) %>%
  mutate(name = replace(name, name == "vacuole organization", "Endosomal transport, Transmembrane transport, vacuole organization, endocytosis, Golgi vesicle transport, membrane fusion, vesicle organization, lipid metabolic process, and protein targeting")) %>%
  mutate(name = replace(name, name == "endocytosis", "Endosomal transport, Transmembrane transport, vacuole organization, endocytosis, Golgi vesicle transport, membrane fusion, vesicle organization, lipid metabolic process, and protein targeting")) %>%
  mutate(name = replace(name, name == "Golgi vesicle transport", "Endosomal transport, Transmembrane transport, vacuole organization, endocytosis, Golgi vesicle transport, membrane fusion, vesicle organization, lipid metabolic process, and protein targeting")) %>%
  mutate(name = replace(name, name == "membrane fusion", "Endosomal transport, Transmembrane transport, vacuole organization, endocytosis, Golgi vesicle transport, membrane fusion, vesicle organization, lipid metabolic process, and protein targeting")) %>%
  mutate(name = replace(name, name == "vesicle organization", "Endosomal transport, Transmembrane transport, vacuole organization, endocytosis, Golgi vesicle transport, membrane fusion, vesicle organization, lipid metabolic process, and protein targeting")) %>%
  mutate(name = replace(name, name == "lipid metabolic process", "Endosomal transport, Transmembrane transport, vacuole organization, endocytosis, Golgi vesicle transport, membrane fusion, vesicle organization, lipid metabolic process, and protein targeting")) %>%
  mutate(name = replace(name, name == "protein targeting", "Endosomal transport, Transmembrane transport, vacuole organization, endocytosis, Golgi vesicle transport, membrane fusion, vesicle organization, lipid metabolic process, and protein targeting")) %>%
  
  mutate(name = replace(name, name == "transcription by RNA polymerase I", "Transcription by RNA polymerase I, transcription by RNA polymerase II, mRNA processing, rRNA processing, and RNA catabolic process")) %>%
  mutate(name = replace(name, name == "transcription by RNA polymerase II", "Transcription by RNA polymerase I, transcription by RNA polymerase II, mRNA processing, rRNA processing, and RNA catabolic process")) %>%
  mutate(name = replace(name, name == "mRNA processing", "Transcription by RNA polymerase I, transcription by RNA polymerase II, mRNA processing, rRNA processing, and RNA catabolic process")) %>%
  mutate(name = replace(name, name == "rRNA processing", "Transcription by RNA polymerase I, transcription by RNA polymerase II, mRNA processing, rRNA processing, and RNA catabolic process")) %>%
  mutate(name = replace(name, name == "RNA catabolic process", "Transcription by RNA polymerase I, transcription by RNA polymerase II, mRNA processing, rRNA processing, and RNA catabolic process")) %>%
  
  mutate(name = replace(name, name == "amino acid metabolic process", "Amino acid metabolic process, vitamin metabolic process, generation of precursor metabolites and energy, carbohydrate metabolic process, and nucleobase-containing small molecule metabolic process")) %>%
  mutate(name = replace(name, name == "vitamin metabolic process", "Amino acid metabolic process, vitamin metabolic process, generation of precursor metabolites and energy, carbohydrate metabolic process, and nucleobase-containing small molecule metabolic process")) %>%
  mutate(name = replace(name, name == "generation of precursor metabolites and energy", "Amino acid metabolic process, vitamin metabolic process, generation of precursor metabolites and energy, carbohydrate metabolic process, and nucleobase-containing small molecule metabolic process")) %>%
  mutate(name = replace(name, name == "carbohydrate metabolic process", "Amino acid metabolic process, vitamin metabolic process, generation of precursor metabolites and energy, carbohydrate metabolic process, and nucleobase-containing small molecule metabolic process")) %>%
  mutate(name = replace(name, name == "nucleobase-containing small molecule metabolic process", "Amino acid metabolic process, vitamin metabolic process, generation of precursor metabolites and energy, carbohydrate metabolic process, and nucleobase-containing small molecule metabolic process")) %>%
  
  mutate(name = replace(name, name == "protein glycosylation", "Protein glycosylation, protein folding, protein modification by small protein conjugation or removal, and proteolysis involved in protein catabolic process")) %>%
  mutate(name = replace(name, name == "protein folding", "Protein glycosylation, protein folding, protein modification by small protein conjugation or removal, and proteolysis involved in protein catabolic process")) %>%
  mutate(name = replace(name, name == "protein modification by small protein conjugation or removal", "Protein glycosylation, protein folding, protein modification by small protein conjugation or removal, and proteolysis involved in protein catabolic process")) %>%
  mutate(name = replace(name, name == "proteolysis involved in protein catabolic process", "Protein glycosylation, protein folding, protein modification by small protein conjugation or removal, and proteolysis involved in protein catabolic process")) %>%
   mutate(name = replace(name, name == "chromatin organization", "Chromatin organization"))
GoTerms_R <- GoTerms_R[!duplicated(GoTerms_R),]

#Remove non-used GoTerms
GoTerms_R <- GoTerms_R %>% filter(name != "organelle fission",
                                  name != "telomere organization",
                                  name != "regulation of DNA metabolic process",
                                  name != "response to chemical",
                                  name != "regulation of organelle organization",
                                  name != "organelle fusion",
                                  name != "cytoskeleton organization",
                                  name != "cell wall organization or biogenesis",
                                  name != "DNA-templated transcription elongation",
                                  name != "RNA splicing",
                                  name != "nucleus organization",
                                  name != "regulation of transport",
                                  name != "DNA-templated transcription initiation",
                                  name != "mitochondrion organization",
                                  name != "nucleobase-containing compound transport")


#Order GoTerms and removal or double entries
GoTerms_R <- GoTerms_R[order(GoTerms_R$value, decreasing = TRUE),] %>% distinct(ORF, gene, name, .keep_all = T)

#Preparing data for Heatmap
GoTerms_R <- pivot_wider(GoTerms_R,names_from = name, values_from = value) %>% ungroup() %>% select(-ORF)
GoTerms_R <- as.data.frame(GoTerms_R)
rownames(GoTerms_R) <- GoTerms_R$gene
GoTerms_R <- GoTerms_R %>% select(-gene)
GoTerms_R <- as.matrix(GoTerms_R)



e <- (ifelse(GoTerms_R <= -0.2, 0, NA))



#Figure 4d and S5c

pdf("05_plots/20-Figure_4d_and_S5c.pdf", 
    height = 8,
    width = 25)
pheatmap(t(GoTerms_R), cluster_rows = F,cluster_cols = T,
         breaks = seq(-0.8,0.8, length.out = 10000),
         fontsize_row = 5,
         fontsize_col = 5,
         color = colorRampPalette(c("#f7931e","#ffffff","#0000ff"))(10000),
         cellwidth = 5,
         cellheight = 5,
         gaps_row = 7,
         display_numbers = t(e),
         fontsize_number = 3)

dev.off()


```

### Extension of degradation and Hits in screens

#### MMS

```{r}

MMS_Genes_inLib
Hits_CG_MMS_Del_d2

#Attribute each ORF to a extension
Only_AID <- anti_join(Hits_CG_MMS_Del_d2,MMS_Genes_inLib, by = "ORF") 
Only_Paper <- anti_join(MMS_Genes_inLib,Hits_CG_MMS_Del_d2, by = "ORF")
Both <- intersect(MMS_Genes_inLib[c("ORF")],Hits_CG_MMS_Del_d2[c("ORF")])

MMS_Ext <- rbind((semi_join(CG_MMS_p_d2, Only_AID, by = "ORF") %>% mutate(Extension = "Our screen")),(semi_join(CG_MMS_p_d2, Only_Paper, by = "ORF") %>% mutate(Extension = "Not on our screen")), (semi_join(CG_MMS_p_d2, Both, by = "ORF") %>% mutate(Extension = "Both screens"))) 
MMS_Ext <- as.data.frame(MMS_Ext)

#Attribute each ORF to a category
MMS_Ext_Cat <- inner_join(MMS_Ext[c("ORF","Extension")], mNG_Colonies, by = "ORF", suffix = c(".x",".y"))
MMS_Ext_Cat <- as.data.frame(MMS_Ext_Cat)

#Remove duplicated rows
MMS_Ext_Cat <- MMS_Ext_Cat[!duplicated(MMS_Ext_Cat$ORF),]
rownames(MMS_Ext_Cat) <- MMS_Ext_Cat$ORF


#Quantify how many of each cell localization there is per Category
MMS_Ext_Cat$AID <- ifelse(MMS_Ext_Cat$Extension == "Our screen", TRUE, FALSE)
MMS_Ext_Cat$Paper <- ifelse(MMS_Ext_Cat$Extension == "Not on our screen", TRUE, FALSE)
MMS_Ext_Cat$Both <- ifelse(MMS_Ext_Cat$Extension == "Both screens", TRUE, FALSE)





MMS_Ext_Cat <- MMS_Ext_Cat %>% select(-c(ORF,Extension,plate,gene,mNG_final_ctrl,mNG_ORFnorm_deg)) %>% group_by(Category) %>% summarize_all(sum, na.rm=TRUE) 
colSums(MMS_Ext_Cat %>% select(-c( Category)), na.rm = TRUE)


#Calculate the percentage of each cell localization per Category
MMS_Ext_Cat_perc_quot <- adorn_percentages(MMS_Ext_Cat, denominator = "col", na.rm = TRUE)

#Tables
knitr::kable(MMS_Ext_Cat, caption = "C-terminal Position of the ORF in the Cellular Membrane by Category", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

knitr::kable(MMS_Ext_Cat_perc_quot, caption = "C-terminal Position of the ORF in the Cellular Membrane by Category in percentage", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

#Transform dataset for plotting
MMS_Ext_Cat_plot_quot <- MMS_Ext_Cat_perc_quot %>% pivot_longer(!Category, names_to = "Degradation_Extension", values_to = "amount")

#Figure S5b
ImS5b3 <- ggplot(data = MMS_Ext_Cat_plot_quot) +
  geom_bar(aes(x = Degradation_Extension, y = amount, fill = Category), position = "fill", stat = "identity") +
  theme_light(base_size = 20) +
      theme(legend.text = element_text(size = 18),
            legend.title = element_text(size = 16))+ 
      guides(colour = guide_legend(override.aes = list(size=5))) +
  coord_flip() +
  labs(x = "C-terminal Position of the ORF",
       y = "Percentage of Membrane ORFs at each Category")

print(ImS5b3)

ggsave("05_plots/21-Figure_S5b.pdf", 
    height = 8,
    width = 16)


```

#### HU

```{r}

HU_Int_Genes_inLib
Hits_CG_HU_Del_d2

#Attribute each ORF to a extension
Only_AID <- anti_join(Hits_CG_HU_Del_d2,HU_Int_Genes_inLib, by = "ORF") 
Only_Paper <- anti_join(HU_Int_Genes_inLib,Hits_CG_HU_Del_d2, by = "ORF")
Both <- intersect(HU_Int_Genes_inLib[c("ORF")],Hits_CG_HU_Del_d2[c("ORF")])

HU_Ext <- rbind((semi_join(CG_HU_p_d2, Only_AID, by = "ORF") %>% mutate(Extension = "Our screen")),(semi_join(CG_HU_p_d2, Only_Paper, by = "ORF") %>% mutate(Extension = "Not on our screen")), (semi_join(CG_HU_p_d2, Both, by = "ORF") %>% mutate(Extension = "Both screens"))) 
HU_Ext <- as.data.frame(HU_Ext)

#Attribute each ORF to a category
HU_Ext_Cat <- inner_join(HU_Ext[c("ORF","Extension")], mNG_Colonies, by = "ORF", suffix = c(".x",".y"))
HU_Ext_Cat <- as.data.frame(HU_Ext_Cat)

#Remove duplicated rows
HU_Ext_Cat <- HU_Ext_Cat[!duplicated(HU_Ext_Cat$ORF),]
rownames(HU_Ext_Cat) <- HU_Ext_Cat$ORF


#Quantify how many of each cell localization there is per Category
HU_Ext_Cat$AID <- ifelse(HU_Ext_Cat$Extension == "Our screen", TRUE, FALSE)
HU_Ext_Cat$Paper <- ifelse(HU_Ext_Cat$Extension == "Not on our screen", TRUE, FALSE)
HU_Ext_Cat$Both <- ifelse(HU_Ext_Cat$Extension == "Both screens", TRUE, FALSE)





HU_Ext_Cat <- HU_Ext_Cat %>% select(-c(ORF,Extension,plate,gene,mNG_final_ctrl,mNG_ORFnorm_deg)) %>% group_by(Category) %>% summarize_all(sum, na.rm=TRUE) 
colSums(HU_Ext_Cat %>% select(-c( Category)), na.rm = TRUE)


#Calculate the percentage of each cell localization per Category
HU_Ext_Cat_perc_quot <- adorn_percentages(HU_Ext_Cat, denominator = "col", na.rm = TRUE)

#Tables
knitr::kable(HU_Ext_Cat, caption = "C-terminal Position of the ORF in the Cellular Membrane by Category", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

knitr::kable(HU_Ext_Cat_perc_quot, caption = "C-terminal Position of the ORF in the Cellular Membrane by Category in percentage", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

#Transform dataset for plotting
HU_Ext_Cat_plot_quot <- HU_Ext_Cat_perc_quot %>% pivot_longer(!Category, names_to = "Degradation_Extension", values_to = "amount")

#Figure S5b
ImS5b4 <- ggplot(data = HU_Ext_Cat_plot_quot) +
  geom_bar(aes(x = Degradation_Extension, y = amount, fill = Category), position = "fill", stat = "identity") +
  theme_light(base_size = 20) +
      theme(legend.text = element_text(size = 18),
            legend.title = element_text(size = 16))+ 
      guides(colour = guide_legend(override.aes = list(size=5))) +
  coord_flip() +
  labs(x = "C-terminal Position of the ORF",
       y = "Percentage of Membrane ORFs at each Category")

print(ImS5b4)

ggsave("05_plots/22-Figure_S5b.pdf", 
    height = 8,
    width = 16)


```

#### CPT

```{r}

CPT_Int_Genes_inLib
Hits_CG_CPT_Del_d1

#Attribute each ORF to a extension
Only_AID <- anti_join(Hits_CG_CPT_Del_d1,CPT_Int_Genes_inLib, by = "ORF") 
Only_Paper <- anti_join(CPT_Int_Genes_inLib,Hits_CG_CPT_Del_d1, by = "ORF")
Both <- intersect(CPT_Int_Genes_inLib[c("ORF")],Hits_CG_CPT_Del_d1[c("ORF")])

CPT_Ext <- rbind((semi_join(CG_CPT_p_d1, Only_AID, by = "ORF") %>% mutate(Extension = "Our screen")),(semi_join(CG_CPT_p_d1, Only_Paper, by = "ORF") %>% mutate(Extension = "Not on our screen")), (semi_join(CG_CPT_p_d1, Both, by = "ORF") %>% mutate(Extension = "Both screens"))) 
CPT_Ext <- as.data.frame(CPT_Ext)

#Attribute each ORF to a category
CPT_Ext_Cat <- inner_join(CPT_Ext[c("ORF","Extension")], mNG_Colonies, by = "ORF", suffix = c(".x",".y"))
CPT_Ext_Cat <- as.data.frame(CPT_Ext_Cat)

#Remove duplicated rows
CPT_Ext_Cat <- CPT_Ext_Cat[!duplicated(CPT_Ext_Cat$ORF),]
rownames(CPT_Ext_Cat) <- CPT_Ext_Cat$ORF


#Quantify how many of each cell localization there is per Category
CPT_Ext_Cat$AID <- ifelse(CPT_Ext_Cat$Extension == "Our screen", TRUE, FALSE)
CPT_Ext_Cat$Paper <- ifelse(CPT_Ext_Cat$Extension == "Not on our screen", TRUE, FALSE)
CPT_Ext_Cat$Both <- ifelse(CPT_Ext_Cat$Extension == "Both screens", TRUE, FALSE)





CPT_Ext_Cat <- CPT_Ext_Cat %>% select(-c(ORF,Extension,plate,gene,mNG_final_ctrl,mNG_ORFnorm_deg)) %>% group_by(Category) %>% summarize_all(sum, na.rm=TRUE) 
colSums(CPT_Ext_Cat %>% select(-c( Category)), na.rm = TRUE)


#Calculate the percentage of each cell localization per Category
CPT_Ext_Cat_perc_quot <- adorn_percentages(CPT_Ext_Cat, denominator = "col", na.rm = TRUE)

#Tables
knitr::kable(CPT_Ext_Cat, caption = "C-terminal Position of the ORF in the Cellular Membrane by Category", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

knitr::kable(CPT_Ext_Cat_perc_quot, caption = "C-terminal Position of the ORF in the Cellular Membrane by Category in percentage", output = T) %>%
  kable_styling(c("striped", "bordered"), full_width = TRUE, position = "left")

#Transform dataset for plotting
CPT_Ext_Cat_plot_quot <- CPT_Ext_Cat_perc_quot %>% pivot_longer(!Category, names_to = "Degradation_Extension", values_to = "amount")

#Figure SF5b
ImS5b5 <- ggplot(data = CPT_Ext_Cat_plot_quot) +
  geom_bar(aes(x = Degradation_Extension, y = amount, fill = Category), position = "fill", stat = "identity") +
  theme_light(base_size = 20) +
      theme(legend.text = element_text(size = 18),
            legend.title = element_text(size = 16))+ 
      guides(colour = guide_legend(override.aes = list(size=5))) +
  coord_flip() +
  labs(x = "C-terminal Position of the ORF",
       y = "Percentage of Membrane ORFs at each Category")

print(ImS5b5)

ggsave("05_plots/23-Figure_S5b.pdf", 
    height = 8,
    width = 16)


```

### Partial degraded and Essential

```{r}

Drug_Hits_Ess <- rbind((semi_join(Drug_Hits, Ess_Genes_inLib, by = "ORF") %>% mutate(Essential = T)), (anti_join(Drug_Hits, Ess_Genes_inLib, by = "ORF") %>% mutate(Essential = F)))

Category <- read.xlsx(xlsxFile = "06_datasets/Categorizationp5.xlsx", sheet = "Sheet 1") %>%
  select(ORF, gene, Category)

Drug_Hits_Cat <- left_join(Drug_Hits_Ess, Category, by = c("ORF","gene"))

```

## Preparing datasets
```{r}


Viability_Screen_final <- rbind((semi_join(Viability_Screen, Hits_IAA_d1_quot, by = "ORF") %>% mutate(Screen = "Hit")), ((anti_join(Viability_Screen, Hits_IAA_d1_quot, by = "ORF") %>% mutate(Screen = "Not_Hit"))))

CG_MMS_p_d2_final <- rbind((semi_join(CG_MMS_p_d2, Hits_CG_MMS_d2, by = "ORF") %>% mutate(Screen = "Hit")), ((anti_join(CG_MMS_p_d2, Hits_CG_MMS_d2, by = "ORF") %>% mutate(Screen = "Not_Hit"))))

CG_HU_p_d2_final <- rbind((semi_join(CG_HU_p_d2, Hits_CG_HU_d2, by = "ORF") %>% mutate(Screen = "Hit")), ((anti_join(CG_HU_p_d2, Hits_CG_HU_d2, by = "ORF") %>% mutate(Screen = "Not_Hit"))))

CG_CPT_p_d1_final <- rbind((semi_join(CG_CPT_p_d1, Hits_CG_CPT_d1, by = "ORF") %>% mutate(Screen = "Hit")), ((anti_join(CG_CPT_p_d1, Hits_CG_CPT_d1, by = "ORF") %>% mutate(Screen = "Not_Hit"))))

Description <- read.xlsx(xlsxFile = "06_datasets/Description.xlsx", sheet = "Description") %>% select(-Gene)

Viability_Screen_final <- left_join(Viability_Screen_final,Description, by = "ORF")


```


# R Studio Session Info

```{r Session info}
sessionInfo()

output_folder <- "07_output/"




write.xlsx(
  x = list("Viability_Screen" = Viability_Screen_final,
           "MMS_Chemical-genetic" = CG_MMS_p_d2_final,
           "HU_Chemical-genetic" = CG_HU_p_d2_final,
           "CPT_Chemical-genetic" = CG_CPT_p_d1_final),
  file = paste0(output_folder, "Library_v2_final_table.xlsx")
)




```

